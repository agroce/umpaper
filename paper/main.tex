%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%%
%% IMPORTANT NOTICE:%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,review, anonymous]{acmart}
\acmConference[ICSE 2024]{46th International Conference on Software Engineering}{April 2024}{Lisbon, Portugal}

\usepackage{code}
\usepackage{graphicx}
\usepackage{balance}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{subfig}
\usepackage{url}
\usepackage{comment}
\usepackage{xcolor}
\usepackage{xspace}

\usepackage{tabularx} % for tables with adjustable column width
\usepackage{makecell} % for formatting table cell contents

\definecolor{dkgreen}{rgb}{0,0.5,0}
\definecolor{dkred}{rgb}{0.5,0,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}

\lstdefinestyle{javastyle} {
language=Java,
basicstyle=\ttfamily\bfseries\footnotesize,
  morekeywords={virtualinvoke},
  keywordstyle=\color{blue},
  ndkeywordstyle=\color{red},
  commentstyle=\color{dkred},
  stringstyle=\color{dkgreen},
  numbers=left,
  breaklines=true,
  numberstyle=\ttfamily\footnotesize\color{gray},
  stepnumber=1,
  numbersep=10pt,
  backgroundcolor=\color{white},
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
  xleftmargin=.23in
}
\lstset{style=javastyle}

%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Syntax Is All You Need: A Universal-Language Approach to Mutant Generation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\author{Alex Groce}
%\affiliation{\institution{Northern Arizona University}\country{United States}}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.

%% Table shortcuts
\newcommand{\mr}[2]{\multirow{#1}{*}{#2}}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}
\newcommand{\um}{\texttt{universalmutator}\xspace}
%% comments
\newcommand{\clg}[1]{\textcolor{blue}{#1}}
\newcommand{\adg}[1]{\textcolor{purple}{#1}}
\newcommand{\kj}[1]{\textcolor{olive}{#1}}

%% numbers
\newcommand{\averageprojvariance}{402}
\newcommand{\averagevariance}{604}
\newcommand{\outliertotalfiles}{26}
\newcommand{\outliertestissues}{12}
\newcommand{\outlierumissues}{7}
\newcommand{\outlierunclear}{7}
\newcommand{\allcorr}{0.7479}
\newcommand{\covcorr}{0.2066}
\newcommand{\allrsquared}{0.573}
\newcommand{\allr}{0.757}
\newcommand{\covrsquared}{0.021}
\newcommand{\covr}{0.145}

\begin{document}

\begin{abstract}
While mutation testing has been a topic of academic interest for
decades, it is only recently that ``real-world'' developers, including
industry leaders such as Google and Meta, have adopted mutation
testing.  In this paper we propose a new approach to the development of mutation
testing tools, and in particular the core challenge of
\emph{generating mutants}.  Current practice tends towards two
limited approaches to mutation generation: mutants are either (1)
generated at the bytecode/IR level, and thus neither human readable
nor adaptable to source-level features of languages or projects, or
(2) generated at the source level by language-specific tools that are
hard to write and maintain, and in fact are often abandoned by both
developers and users.  We propose instead that source-level mutation
generation is a special case of \emph{program transformation} in
general, and that adopting this approach allows for a single tool that
can effectively generate source-level mutants for essentially
\emph{any} programming language. Furthermore, by using \emph{parser
  parser combinators} many of the seeming limitations of an
any-language approach can be overcome, without the need to parse
specific languages.  We compare the universal program transformation
approach to mutation to existing tools, and demonstrate the advantages
of using parser parser combinators to improve on a simple regular-expression
based approach to generation.  
\end{abstract}


\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10010940.10010992.10010998.10011001</concept_id>
<concept_desc>Software and its engineering~Dynamic analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011074.10011099.10011102.10011103</concept_id>
<concept_desc>Software and its engineering~Software testing and debugging</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Dynamic analysis}
\ccsdesc[500]{Software and its engineering~Software testing and debugging}

\maketitle



\section{Introduction}

Mutation testing, though introduced in the late
1970s~\cite{demillo1978hints,mathur2012foundations,demillo1978hints},
has largely been a topic of academic interest rather than widespread
practice until quite recently.  However, with the adoption of mutation
testing by bellwether software industry companies including
Google~\cite{GoogleMut}, Meta~\cite{BellerFacebookMutation}, and
Amazon~\cite{AmazonMut}, interest in using mutation testing for
real-world projects has grown widely.

Interest in mutation testing has become widespread enough in the open
source community that a popular (more than 300 stars on GitHub)
repository, ``Awesome Mutation Testing,'' lists more than 40 tools,
covering almost twenty languages:
\url{https://github.com/theofidry/awesome-mutation-testing}.  Some of
these tools are the products of academic research, but many are
essentially the hobby projects of developers interested in enabling
mutation testing for their favorite language.

However, the same website demonstrates the existence of a sad history
of mutation testing tools: mutation tools have a tendency to be
developed for a while and then abandoned.   The page listing abandoned
mutation testing tools
(\url{https://github.com/theofidry/awesome-mutation-testing/blob/master/abandoned.md})
lists almost half as many tools as are under active maintenance, and
these tools cover approximately half as many languages.  Each of these
tools required considerable development time and effort, and was
popular enough at some point to be worth noting in the ``Awesome
Mutation Testing'' resource.  Many of the abandoned tools have GitHub
repositories (some archived) with more than 20 stars, and so may well
have had users who at some point faced the reality of no future bug
fixes or changes to address changes to the programming language being
mutated\footnote{While this is a minor concern for languages such as C
  that are relatively stable, it means that a mutation tool may fail
  to parse C++ 2020, and is particularly problematic for somewhat
  fast-moving languages such as Rust.}.  There
appears to be a significant risk in relying on any mutation tools other
than the most widely used and well-supported, such as PIT.

Moreover, newer languages, including ones with considerable interest
in the development community, often lack mutation testing tools.  Even
languages with a long history may long lack a working mutation testing
tool; e.g., it was not until 2014 that Haskell had such a tool
\cite{mucheck}.  Furthermore, that tool is no longer
supported\footnote{The last commits or package updates were in 2015, and the
primary author confirms that changes to {\tt haskell-src-ext} since
introduced render it unusable at present.}, and it
appears that no successor tool has appeared in the ensuing
years\footnote{There is FitSpec \cite{FitSpec}, which is maintained,
  but FitSpec does not perform traditional mutation testing or produce
  source code (or bytecode) mutants; it rather
  performs black-box type-aware mutation of function return values.}.
Haskell developers (until now, see below) have no option for
performing true mutation testing.

A great deal of research effort has been devoted to devising clever
schemes for reducing the computational burden of mutation testing over
the years; in practice, however, the recent adoption of mutation
testing arguably relies more on the availability of vast (cloud) computing
resources than any particular approach from the literature, beyond
heuristic restrictions on the mutants used (e.g., one per line, or
only some siimple operators).   On the other hand, almost no
research has addressed perhaps the most central issue of
mutation testing: in the absence of a working mutation testing
tool for the language in which one is developing software, one cannot
obtain the benefits of mutation testing.  The absence of such tools is
due to the high human cost of developing and maintaining mutation
testing tools.  Ideally, mutation testing would be available for
\emph{any} newly proposed programming language, as soon as that
language has any community of users at all.  In the present
state-of-the-art, however, it may be years before even rudimentary
tools appear, and they may ``disappear'' shortly there-after.

In this paper, we argue that developing a large number of mutation
testing tools, each requiring its own development community, workflow
for mutation, and effort to keep up with language changes, is fundamentally
unnecessary.  The core problem of mutation testing,
\emph{mutant generation}, is simply a particular instance of the
problem of \emph{program transformation}.  Program transformation
considers the problem of taking a program, $P$, and producing a
program, $P'$ that is the result of applying some function $f$ to $P$
(i.e., $P' = f(P)$).  In mutant generation, we
consider a family of functions $f$ where each $f_{o,loc}$ is an
instantiation of a \emph{mutation operator} $o$  (as classically, if
often informally, defined in the literature) at a particular program
location $loc$ in $P$.  The inclusion of $loc$ in the specification of
$f$ indicates that the problem is a specialization of general
program transformation in that all classic mutation operators we are
aware of are \emph{local}: they only affect a small portion of a
program, genearlly a contiguous string of characters or tokens.

Moreover, as this suggests,
mutation testing can be treated as an almost entirely \emph{syntactic}
transformation problem; in fact, in their classic introduction to
software testing, Ammann and Offutt refer to mutation testing as
``syntax-based testing'' ~\cite{ammann2016introduction}.  While, e.g., refactoring may need to
``understand'' a program to some extent, mutation can often operate
with essentially no context beyond a single line of code.

We further propose that in fact, for the most part, mutant
generation need not even ``know'' the syntax of a target language, in
terms of a complete grammar.  Instead, mutation testing can operate to
a large extent in a \emph{universal} manner, where programs are
transformed at the level of \emph{patterns of characters}.  That is,
each $o$ and $loc$ can be defined without reference to, e.g., the
context-free grammar of a programming language, but only with respect
to a position in $P$ treated as a string, and a transformation on a
string defined in terms of, e.g., regular expressions with capture and
replacement.  Treating mutant generation as a problem of (textual, local)
program transformation provides two major benefits:

\begin{enumerate}
  \item A single tool can provide mutant generation for almost any
    programming language, without needing to parse that language, and
    rules for one language can be re-used for another language.  This
    reduces the development and maintenance effort for mutation
    testing tools by orders of magnitude.  Moreover, it removes the
    need for many   maintenance activities related to parsing code;
    such changes need to be made only when a change to the language
    would introduce new mutation operators or modify existing ones.
    The local nature of operators tends to make the second case very rare.
    \item The existing literature on multi-lingual or language
      agnostic program transformation can be applied to the problem of
      mutant generation, making it easy to express mutation operators
      that operate across many languages, and efficient to generate
      valid mutants even in the absence of language-specific
      development effort.
      \end{enumerate}

The contributions of this paper are therefore:

\begin{enumerate}
  \item The description of a novel approach to mutant generation
    based on generalized description of multi-lingual program transformations
    that allows a single tool to handle mutant generation for
    essentially all programming languages.  This approach also makes
    mutation testing almost trivial to extend to most new languages and even allows
    developers to write project-specific rules easily without
    having to modify a mutation tool's implementation.

          \item A proposal to use parser parser combinators to improve the
      efficiency and expressive power of that approach, and an
      evaluation of the gains thus achieved.

    
      \item A comparison of an implementation of mutant generation
       based on this approach with existing tools for four important
       programming languages.  The single-language tools range from
       approximately 3,800 LOC to nearly 60,000 LOC, and, we emphasize, each handle
       one programming language.  Our tool, which provides comparable
       core mutation testing functionality, supports over a dozen
       languages using only about 2,200 LOC of Python and less than 500
       lines for rules defining mutation operators over a dozen
       specific languages (and which can effectively mutate an
       essentially unlimited number of other languages).

       \item A small case study showing that our approach produces
         useful results, even without the definition of
         language-specific rules, for Haskell, a language arguably
         well outside the language paradigms we considered when
         developing the universal mutation rules.

\end{enumerate}


\section{The Universal Language Source-Based Approach}

The key insight of this paper is that \emph{most mutation operators
  proposed in the literature do not in fact require parsing of source
  code.}  Consider, for example, one of the most commonly used
mutation operators, replacement of arithmetic operations.  We do not
need to parse a program containing the string {\tt ``x + y''} in order to
replace that string with {\tt ``x - y''}.  Instead, this change is
guaranteed to be effected if we simply search the program, represented
as a string, for all occurrences of  {\tt ``+''}, and produce for each
such occurrence, a mutant where tha character is replaced by {\tt
  ``-''}.  We can do the same for each pair of arithmetic operations,
and thus trivially implement a large fraction of the classic Mothra~\cite{offutt1996experimental}
mutation operators.

The obvious objection to this simplistic approach is that unless we
parse the code to identify arithmetic expressions, some of these
replacements will be invalid.  E.g., in a C++ program we will produce
mutants like {\tt x-+} replacing {\tt x++}.  However, most of these
instances can be avoided by slightly more judicious choice of search
target: instances of {\tt ``+''} where the preceeding or following
character is not another {\tt ``+''}, for instance.

Of course, in some cases this will still leave us with invalid
mutants.  However, rejecting such mutants is easy: the truly invalid
mutants will fail to compile.  Of course, we must pay the price of
checking each mutant to make sure that it does compile, at generation
time.

However, consider what has been gained by paying this cost.  We have
replaced a complex implementation, that requires parsing source code,
with an implementation that only requires string search-and-replace.
One can imagine an implementation of the above approach to arithmetic
operation replacement being implemented in as little as 10-20 lines of
Python code, including a call to a compiler to check for invalid
mutants.  Moreover, defining new mutation operators is not a matter of
understanding a representation of a parsed program, but is essentially
a matter of providing two strings, where the second is a proposed
replacement for the first.  Instead of code for arithmetic operator
replacement, we can imagine the above hypothetical Python program
reading in a file of thus expressed mutation operators, and
implementing an unbounded number of operators in a minimalist fashion.

Of course, simple string replacement is not general enough to handle
many interesting mutations.  Consider the classic case of statement
deletion, one of the most widely used and important mutation
operators~\cite{deng2013empirical}.  What string can we replace with another string in order to
delete a statement in a C program?  We would need an ``operator'' for
each possible C statement.  However, if we allow the use of
\emph{regular expression match and replace pairs} in place of simple
strings, we can easily express this operator, with some precision:

\begin{verbatim}
(^\s*)(\S+[^{}]+.*)\n ==> \1/*\2*/\n
\end{verbatim}

In Python regular expression syntax, this expresses the replacement of
strings with a possibly-empty amount of white space followed by a
character pattern indicating a line of source code, with the same
source code, preserving indentation, turned into a comment.

Using regular expressions to express mutants has many benefits.  While
much more expressive than simple string replacement, regular
expressions are familliar to most developers.  In principle,
development of complex regular expressions for operators can even be
performed by simply providing examples~\cite{bartoli2014automatic}  or
describing the operator in natural
language~\cite{zhong2018generating}.  Implementing a mutation
generation tool for a language by providing the equivalent of our
Python program above with a list of regular expression matches and
replacements is clearly much easier than writing a mutation tool from
scratch, and much easier to maintain and extend. 

\subsection{Hierarchies of Operator Applicability}

Implementing mutant generation by providing a set of regular-expression
based textual transformations for each target language, and using a
single engine to apply rules to source files is certainly less
difficult in terms of development and maintenance effort than building
a tool for each language around a parser for that language.  However,
even this approach ignores one of the primary benefits of a universal,
text-based approach.  Consider the case of replacing instances of {\tt
  ``+''}  with {\tt ``-''}.  This mutation is not tied to any
particular language, but applies to \emph{almost all programming
  languages in use.}  Many of the most widely used mutation operators
in the literature are of this universal nature.  Others are not quite
so widely applicable, but still apply to a large number of specific
languages.  E.g., many programming languages share C's logical
operators, though important exception such as Python and Lisp-family
languages do not.

Implementing a tool for a language $L$ therefore, generally need not
require writing rules for all mutation operators to be applied to $L$
programs, but instead can proceed by process of 1) identifying $L$'s
place in a \emph{hierarchy} of language \emph{famillies}, and then 2)
identifying additional operators needed for $L$ itself.  The first of
these tasks is often trivial, as in practice there are only a few
basic syntactic forms for languages, at the level needed to describe
transformation rules for operators.  In fact, ignoring the second step
will often provide ``good-enough'' mutation testing, in that, for
example, most of the Mothra rules and statement deletion can be
entirely handled without descending to the specific-language level at all.

As an
example, consider mutation of Java code.  Many Java mutants can be
generated by the kind of ``universal'' rules (e.g., arithmetic
operator replacements) considered above.  Other mutation operators
suitable for Java source are provided by considering the set of
``C-like'' languages that use the logical operators and control
constructs common to e.g.,  Java, C, and C++ ({{\tt if}, {\tt while},
  etc.).  Statement deletion at the line level can also be implemented
  by using the common comment notation for such languages.
  Implementing Java mutation, given universal and C-like rules, may
  require no more than a handful of additional rules.

\begin{table}[hbtp]
\centering
\caption{Rule Examples}
\label{tab:rules}
\resizebox{\columnwidth}{!}{%

  \begin{tabular}{|l|l|l|}
    \hline
    Universal & C-Like & Language-Specific \\
    \hline
{\tt < ==> >} &{\tt  else ==>} & {\tt synchronized ==>} \\ 
{\tt < ==> ==} & {\tt if (\textbackslash(.*\textbackslash)) ==> if (!\textbackslash 1)} &
                                                                 {\tt (\^{}\textbackslash s*)(\textbackslash S+.*\textbackslash n) ==> \textbackslash 1pass}\\
{\tt < ==> <=} & {\tt if (\textbackslash(.*\textbackslash)) ==> if
                 (1==1)} & {\tt any\_of ==> all\_of}\\
\hline

\end{tabular}
}

\end{table}
  
  
  Table~\ref{tab:rules} shows examples of universal, C-like, and
  language-specific rules for a few languages, taken directly from our
  implementation.  In all cases, the form of a rule is: {\tt regexp
    ==> replacement}, using Python regular expression and replacement syntax.

  The first column shows universal rules applied to
  all languages, here drawn from the large set of transformations for
  less-than comparisons.  The second column shows somewhat more
  complex rules, for removing elses (which always leaves valid code in
  C-like languages, but with the else clause always executing) and for
  replacing if conditions with, respectively, a negation and a
  constantly true expression.  Finally, the last column shows
  language-specific rules, for, respectively, Java, Python (statement
  deletion, including a {\tt pass} and respecting indentation level),
  and C++.  The last rule was contributed by a user using our tool to
  perform mutation testing on the bitcoin core implementation.  For a
  C++ program, all of the rules in the first two columns will be
  applied, as well as the last rule in the third column.  For a Python
  program, however, only the first column of rules and the second rule
  in the last column apply, as Python is not sufficiently ``C-like''.


\subsection{Incremental Mutation}

One obvious concern with any-language source-based mutation is that every time the
program changes, the cost of invalid mutations must be paid again.
However, the locality of mutants and source changes in fact means this
is seldom required.

The {\tt git merge-file} utility takes a base file and two modified
versions of that file, and produces an automatic merge, using the
usual git merge resolution algorithm.    Because a mutant is a (very
small) source change, this means that in practice updating a mutant to
reflect even large changes to a source file is cost-free, and if the
original mutant was valid, the new mutant will usually also be valid.
New mutant generation is only required for new lines of code and
modified lines of code.  To the extent development is incremental,
therefore, mutant generation can also be incremental.

\section{Beyond Regular Expressions with Parser Parser Combinators}
% Better to frame this as "Beyond regex with PPC" than "PPC instead of RE" 
% instead of RE" because RE pattern matching can be implemented by PPCs,
% they are just pattern matching functions that can be restricted to lexical
% RE-style matching too, and, e.g., comby embeds PCRE regex matching support,
% as a parser combinator). In this sense, PPCs _really are_ a better/more
% general/more universal matching engine abstraction at the expressivity level
% where we care about mutating source syntax with CFG properties.

We implement a lightweight parser-driven approach that attunes mutation
operators to language-general syntax-aware transformations. For example, our
operators can ensure syntactically well-formed outputs (e.g., transformations
must preserve balanced parentheses or braces). More generally, operators are
sensitive to coarse-grained context-free grammar properties. These operators go
beyond the expressivity of regular expressions (which are typically limited to
lexical transformations) to generate \emph{varied} and \emph{valid}
programs during mutation testing.

Parser parser combinators~\cite{vanTonderPPC} is a recent approach enabling
syntax-transformation for multiple languages, and (we show) an apt choice for
mutation testing operators. This key idea is to replace code constructs
common to many languages (e.g., multi-line code blocks delineated by braces)
with simple declarative patterns. Using parser combinators for coarse syntax
matching avoids the complexity of integrating heterogeneous rewrite tools for
mutation testing (e.g., one for Java, one for C++) and human effort to
implement language-specific mutation operators (e.g., where the user has to
learn to write operators for each language tool). The mechanization and
expressive properties of parser parser combinators is covered in prior
literature~\cite{vanTonderPPC}; in this paper we demonstrate that their application is
uniquely effective for universal source-based mutation testing. In
particular, we
build mutation operators with \texttt{comby},\footnote{https://comby.dev} the tool that implements parser parser
combinators to declaratively match and rewrite source code syntax. 

Comby is especially suited for matching multi-line code blocks and
disambiguating code from comments and strings---constructs that otherwise
confound and complicate regular expression patterns. Comby supports over 40
languages and implements a generic parser for additional languages to recognize
these syntactic constructs. The following is a brief overview of Comby
definitions and syntax for mutation operators implemented in our approach:

\begin{itemize}

\item \texttt{\small:[hole]} syntax matches source code assigned to a variable \emph{hole}. Holes match all characters (including whitespace) lazily up to its suffix (analogous to \texttt{\small.*?} in regex), but only \emph{within} its level of balanced delimiters. For example, \texttt{\small\{:[hole]\}} will match all characters inside balanced braces. By default, parentheses and square brackets are also treated as balanced delimiters, as applicable to most languages. 

\item \texttt{\small ":[x]"} matches the body of a well-quoted string. Unlike \texttt{\small :[x]} (without quotes), the quoted variety implies that a data string may be any value, including strings that contain unbalanced parentheses, like \texttt{\small "item)"}.

\item \texttt{\small:[hole:e]} matches words like \texttt{\small hello} and contiguous well-balanced expression-like syntax, like \texttt{\small print("hello world")} or \texttt{\small (a + b)}. It stops matching at whitespace boundaries, and so does not match a string like \texttt{\small a + b}. It also does not match unbalanced code syntax like \texttt{\small foo)} in typical languages where expressions are expected to be well-balanced.

\item \texttt{\small :[[hole]]} matches alphanumeric characters in source code (similar to \texttt{\small\textbackslash w+} in regex).

\item When a variable \emph{hole} occurs multiple times in a match template, the matched matched values be equal.

\item Non-whitespace characters are matched literally.

\item Contiguous whitespace (e.g., spaces and newline) match contiguous whitespace in the source code. That is, match templates are sensitive to the \emph{presence} of whitespace, but \emph{not} the exact layout of spaces (i.e., the number of spaces may not correspond exactly between match template and source code).

\item Matching is insensitive to comments. Comments are parsed as whitespace when matching non-hole syntax in the match template.

\end{itemize}

Comby provides mechanisms to further define custom match syntax and behavior
beyond these standard patterns.\footnote{https://comby.dev/docs/advanced-usage\#custom-language-definitions} \texttt{Comby} patterns can also embed regular expressions, subsuming their
expressive power to enable regex-based mutation operators intermixed with
context-free syntax properties.\footnote{https://comby.dev/docs/basic-usage\#using-regular-expressions}

\section{Implementation}

We implemented our approach in a mutation testing tool, written in
about 2,200 lines of Python.  The rules defining mutation operators
for a set of languages including C, C++, Python, Java, Lisp, Swift,
Rust, Solidity, Fe, Vyper, JavaScript, and Go, required another 436
lines; this is the total for comby and regexp-based rules, so each
version requires only 218 lines of rule definitions.

While many tools provide a GUI front-end, or integrate to a particular
testing library, we chose to focus on an easily configured CLI,
allowing a user to specify the commmands used to build mutants or
run tests.  While less convenient in the case where there is a good
fit between a tool's integrations and a project's environment, we
found this flexibility useful even when limiting considerations to a
single language.  For example, the widely used PIT system is strongly tied to
certain versions of JUnit, and mutating projects using a different
testing infrastructure, or an older JUnit, can be difficult.  Our
approach also is suitable for use in CI and other automated environments.

For the most part we expect users to provide build commands, but do
support automatic compilation and comparison of mutants for Python,
Solidity, Fe, Vyper, Swift, Rust, and Java, including Trivial Compiler
Equivalence \cite{TCE} checks for redundancy of mutants.  These
default handlers can always be over-ridden if they do not work with a
particular build setup.

Our tool has been available as an open source project on GitHub and
available for installation via Python pip for
some time, has received contributions from users not involved in
our project, and been adopted by at least one very large project as
the officially recommended mutation tool.  We omit details for
purposes of blinding.

\section{Experimental Evaluation}

\begin{itemize}

  \item{RQ1:}  How does the use of parser parser combinators modify 
    the efficiency (in terms of invalid mutants) and effectiveness (in
    terms of mutation score and equivalent mutants) of the universal
    approach to mutant generation?

\item{RQ2:}  How does the univeral approach, using regular expressions
  or parser parser combinator rules, compare to existing
  single-language mutation tools, in terms of number of generated
  mutants, mutation scores, equivalent mutants, and other evaluation measures used in the literature?

\end{itemize}


Both research questions were addressed by generating and running
mutants for a set of four programming languages: C++, Java, Python,
and Rust.  We picked six projects with 1) a large number of GitHub
stars and 2) an easy-to-execute, passing test suite for each language,
and then chose the largest source file below 20KB in size from each project to mutate.  Limiting
mutation to one large but not extremely large file made is easier to compare generated mutants and
manually inspect for mutant equivalency.  The only bias to file
selection was size, which we do not believe should affect our results
significantly.

We additionally present a small
case study, applying our implementation to a program in a language for
which it has \emph{no} rules, Haskell.

\subsection{Regular Expressions vs. Parser Parser Combinators}


% ---------------- C++ table UM Only--------------------------
\begin{table}[hbtp]
\centering
\caption{C++ (Regex vs. Comby)}
\label{tab:table_cpp1}
\resizebox{\columnwidth}{!}{%

\begin{tabular}{|c|c|c|r|r|r|}
\hline
 & \multicolumn{2}{c|}{} & \textbf{Valid} & \textbf{Invalid} & \textbf{Valid \%}  \\ \hline
\multirow{2}{*}{ompl} & \multicolumn{2}{c|}{Regex} & 595 \hspace{8pt} & 1938 \hspace{8pt} & 23.49\%  \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 564 \hspace{8pt} & 1610 \hspace{8pt} & 25.94\% \\ \hline
\multirow{2}{*}{libgraphqlparser} & \multicolumn{2}{c|}{Regex} & 157 \hspace{8pt} & 584 \hspace{8pt} & 21.19\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 131 \hspace{8pt} & 309 \hspace{8pt} & 29.77\% \\ \hline
\multirow{2}{*}{rethinkdb\_rebirth} & \multicolumn{2}{c|}{Regex} & 545 \hspace{8pt} & 1701 \hspace{8pt} & 24.27\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 492 \hspace{8pt} & 1517 \hspace{8pt} & 24.49\% \\ \hline
    
\multirow{2}{*}{xoreos} & \multicolumn{2}{c|}{Regex} & 2419 \hspace{8pt} & 1457 \hspace{8pt} & 62.41\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 2280 \hspace{8pt} & 1017 \hspace{8pt} & 69.15\% \\ \hline
\multirow{2}{*}{libxmljs} & \multicolumn{2}{c|}{Regex} & 881 \hspace{8pt} & 3108 \hspace{8pt} & 22.09\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 790 \hspace{8pt} & 3218 \hspace{8pt} & 19.71\% \\ \hline
\multirow{2}{*}{tiny-differentiable-simulator} & \multicolumn{2}{c|}{Regex} & 747 \hspace{8pt} & 535 \hspace{8pt} & 58.27\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 770 \hspace{8pt} & 444 \hspace{8pt} & 63.43\% \\ \hline

\multirow{6}{*}{Overall} & \multirow{3}{*}{Regex} & Mean & 890.67 &	1553.83 & 35.28\%\\\cline{3-6}
    &   &  Median & 671.00 & 1579.00 & 23.88\%  \\\cline{3-6}
    &   &  Std. Dev & 787.62 & 956.31 & 19.48\%  \\\cline{2-6}

 & \multirow{3}{*}{Comby} & Mean & 837.83 & 1352.50 & 38.75\% \\\cline{3-6}
    &   &  Median & 667.00 & 1267.00 & 27.86\%  \\\cline{3-6}
    &   &  Std. Dev & 745.78 & 1058.33	& 21.66\%  \\\hline

\end{tabular}
}

\end{table}

  

% ---------------- JAVA table UM Only--------------------------
\begin{table}[hbtp]
\centering
\caption{Java (Regex vs. Comby)}
\label{tab:table_java1}
\resizebox{\columnwidth}{!}{%

\begin{tabular}{|c|c|c|r|r|r|}
\hline
 & \multicolumn{2}{c|}{} & \textbf{Valid} & \textbf{Invalid} & \textbf{Valid \%}  \\ \hline
\multirow{2}{*}{pebble} & \multicolumn{2}{c|}{Regex} & 86 \hspace{8pt} & 928 \hspace{8pt} & 8.48\%  \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 85 \hspace{8pt} & 667 \hspace{8pt} & 11.30\% \\ \hline
\multirow{2}{*}{spring-hateoas} & \multicolumn{2}{c|}{Regex} & 248 \hspace{8pt} & 2231 \hspace{8pt} & 10.00\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 172 \hspace{8pt} & 1212 \hspace{8pt} & 12.43\% \\ \hline
\multirow{2}{*}{javacc} & \multicolumn{2}{c|}{Regex} & 542 \hspace{8pt} & 1346 \hspace{8pt} & 28.70\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 494 \hspace{8pt} & 782 \hspace{8pt} & 38.71\% \\ \hline
    
\multirow{2}{*}{coffee-gb} & \multicolumn{2}{c|}{Regex} & 224 \hspace{8pt} & 1703 \hspace{8pt} & 11.63\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 174 \hspace{8pt} & 624 \hspace{8pt} & 21.80\% \\ \hline
\multirow{2}{*}{egads} & \multicolumn{2}{c|}{Regex} & 624 \hspace{8pt} & 1830 \hspace{8pt} & 25.43\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 597 \hspace{8pt} & 566 \hspace{8pt} & 51.33\% \\ \hline
\multirow{2}{*}{apk-parser} & \multicolumn{2}{c|}{Regex} & 351 \hspace{8pt} & 1232 \hspace{8pt} & 22.17\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 333 \hspace{8pt} & 866 \hspace{8pt} & 27.77\% \\ \hline

\multirow{6}{*}{Overall} & \multirow{3}{*}{Regex} & Mean & 345.83 & 1545.00  & 17.74\%\\\cline{3-6}
    &   &  Median & 299.50 & 1524.50 & 16.90\%  \\\cline{3-6}
    &   &  Std. Dev & 203.86 & 467.98 & 8.73\%  \\\cline{2-6}

 & \multirow{3}{*}{Comby} & Mean & 309.17 & 786.17 & 27.22\% \\\cline{3-6}
    &   &  Median & 253.50 & 724.50 & 24.79\%  \\\cline{3-6}
    &   &  Std. Dev & 202.44 & 235.24  & 15.59\%  \\\hline


\end{tabular}

}
\end{table}

% ---------------- Python table UM Only --------------------------

\begin{table}[hbtp]
\centering
\caption{Python (Regex vs. Comby)}
\label{tab:table_python1}
\resizebox{\columnwidth}{!}{%

\begin{tabular}{|c|c|c|r|r|r|r|}
\hline
 & \multicolumn{2}{c|}{} & \textbf{Valid} & \textbf{Invalid} & \textbf{Redundant} & \textbf{Valid \%}  \\ \hline
\multirow{2}{*}{keract} & \multicolumn{2}{c|}{Regex} & 1655 \hspace{8pt} & 1600 \hspace{8pt} &	729 \hspace{8pt} & 41.53\%  \\\cline{2-7}
    & \multicolumn{2}{c|}{Comby} & 1471 \hspace{8pt} & 1063 \hspace{8pt} & 533 \hspace{8pt} & 47.96\% \\ \hline
\multirow{2}{*}{dtw} & \multicolumn{2}{c|}{Regex} & 973 \hspace{8pt} & 566 \hspace{8pt} & 567 \hspace{8pt} & 46.20\% \\\cline{2-7}
    & \multicolumn{2}{c|}{Comby} & 866 \hspace{8pt} & 330 \hspace{8pt} & 639 \hspace{8pt} &	47.19\% \\ \hline
\multirow{2}{*}{notion-sdk-py} & \multicolumn{2}{c|}{Regex} & 196 \hspace{8pt} & 760 \hspace{8pt} & 82 \hspace{8pt} & 18.89\% \\\cline{2-7}
    & \multicolumn{2}{c|}{Comby} & 196 \hspace{8pt} & 701 \hspace{8pt} & 122 \hspace{8pt} & 19.23\% \\ \hline
    
\multirow{2}{*}{{\makecell{atlassian-python \\ api}}} & \multicolumn{2}{c|}{Regex} & 302 \hspace{8pt}	& 1002 \hspace{8pt} & 207 \hspace{8pt} &	19.99\% \\\cline{2-7}
    & \multicolumn{2}{c|}{Comby} & 333 \hspace{8pt} & 635 \hspace{8pt} & 351 \hspace{8pt} & 25.25\% \\ \hline
\multirow{2}{*}{ESD} & \multicolumn{2}{c|}{Regex} & 1859 \hspace{8pt}	& 2767 \hspace{8pt} & 1642 \hspace{8pt} & 29.46\% \\\cline{2-7}
    & \multicolumn{2}{c|}{Comby} & 1712 \hspace{8pt} & 1548 \hspace{8pt} &	614 \hspace{8pt} & 44.18\% \\ \hline
\multirow{2}{*}{fiber} & \multicolumn{2}{c|}{Regex} & 493 \hspace{8pt} & 909 \hspace{8pt} & 163 \hspace{8pt} & 31.08\% \\\cline{2-7}
    & \multicolumn{2}{c|}{Comby} & 458 \hspace{8pt} & 767 \hspace{8pt}	& 241 \hspace{8pt} & 31.24\% \\ \hline

\multirow{6}{*}{Overall} & \multirow{3}{*}{Regex} & Mean & 913.00 & 1267.33 & 565.00 & 31.19\%   \\\cline{3-7}
    &   &  Median & 733.00 & 955.50 & 387.00 & 30.27\%  \\\cline{3-7}
    &   &  Std. Dev & 708.93 & 813.35 & 584.79 & 11.06\%  \\\cline{2-7}

 & \multirow{3}{*}{Comby} & Mean & 839.33 & 840.67 & 416.67 & 35.84\% \\\cline{3-7}
    &   &  Median & 662.00 & 734.00 & 442.00 & 37.71\%  \\\cline{3-7}
    &   &  Std. Dev & 628.79 & 418.99 & 211.62 & 12.28\%  \\\hline

\end{tabular}

}
\end{table}


% ---------------- Rust table UM Only --------------------------
\begin{table}[hbtp]
\centering
\caption{Rust (Regex vs. Comby)}
\label{tab:table_rust1}
\resizebox{\columnwidth}{!}{%

\begin{tabular}{|c|c|c|r|r|r|}
\hline
 & \multicolumn{2}{c|}{} & \textbf{Valid} & \textbf{Invalid} & \textbf{Valid \%}  \\ \hline
\multirow{2}{*}{cargo release} & \multicolumn{2}{c|}{Regex} & 851 \hspace{8pt} &	1163 \hspace{8pt} & 42.25\%  \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 1690 \hspace{8pt} & 711 \hspace{8pt} & 70.39\% \\ \hline
\multirow{2}{*}{passerine} & \multicolumn{2}{c|}{Regex} & 213 \hspace{8pt} & 2081 \hspace{8pt} & 9.29\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 173 \hspace{8pt} & 1518 \hspace{8pt} & 10.23\% \\ \hline
\multirow{2}{*}{typos} & \multicolumn{2}{c|}{Regex} & 386 \hspace{8pt} & 1534 \hspace{8pt} & 20.10\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 366 \hspace{8pt} & 1199 \hspace{8pt} &	 23.39\% \\ \hline
    
\multirow{2}{*}{ord} & \multicolumn{2}{c|}{Regex} & 762 \hspace{8pt}	& 2096 \hspace{8pt} & 26.66\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 643 \hspace{8pt} & 1669 \hspace{8pt} & 27.81\% \\ \hline
\multirow{2}{*}{bazuka} & \multicolumn{2}{c|}{Regex} & 451 \hspace{8pt} & 1103 \hspace{8pt} & 29.02\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 402 \hspace{8pt} & 920 \hspace{8pt} & 30.41\% \\ \hline
\multirow{2}{*}{strum} & \multicolumn{2}{c|}{Regex} & 51 \hspace{8pt} & 377 \hspace{8pt}	& 11.92\% \\\cline{2-6}
    & \multicolumn{2}{c|}{Comby} & 50 \hspace{8pt} & 318 \hspace{8pt}	& 13.51\% \\ \hline

\multirow{6}{*}{Overall} & \multirow{3}{*}{Regex} & Mean & 452.33 & 1392.33	& 23.21\%\\\cline{3-6}
    &   &  Median & 418.50 & 1348.50 & 23.38\%  \\\cline{3-6}
    &   &  Std. Dev & 309.05 & 656.76 & 12.16\%  \\\cline{2-6}

 & \multirow{3}{*}{Comby} & Mean & 554.00 & 1055.83	& 29.29\% \\\cline{3-6}
    &   &  Median & 384.00 & 1059.50	& 25.60\%  \\\cline{3-6}
    &   &  Std. Dev & 592.63 & 508.30 & 21.63\%  \\\hline


\end{tabular}

}
\end{table}



\subsection{Universal Source-Based Mutation vs. Previous Approaches}


\begin{table}[hbtp]
  \centering
  \caption{Overview of Mutation Testing Tools.}
  \label{tab:mutationtools}
  
  \begin{tabular}{|c|c|r|}
  \hline
  \textbf{Language} & \textbf{Tool} & \textbf{LOC}  \\
  \hline
  \multirow{2}{*}{Python}  & Mutmut &	3870  \\\cline{2-3}
      & cosmic-ray & 4599 \\ \hline
  \multirow{2}{*}{Java}  & PIT &	59577  \\\cline{2-3}
      & LittleDarwin & 22359 \\ \hline
      Rust & Cargo-Mutants & 7020 \\\hline
      C++ & Dextool & 38611 \\\hline
      ALL & universalmutator & 2680 \\\hline
  \end{tabular}
\end{table}

Table \ref{tab:mutationtools} shows the set of tools compared.  We
attempted to identify well-maintained and commonly used tools for each
language chosen.


% ---------------- C++ table (UM vs Others)--------------------------

\begin{table}[htbp]
\centering
\caption{C++ (UniversalMutator vs. Dextool)}
\label{tab:table_cpp2}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|r|r|r|r|}
\hline
 &  & \textbf{Killed} & \textbf{Not Killed} &  \makecell{\textbf{Mutation} \\ \textbf{Score}} & \textbf{Equivalent \%} \\ \hline

 \multirow{3}{*}{\small ompl} & Regex & 29 & 566 & 0.05 & 30\% \\\cline{2-6}
    & Comby & 41 & 523 & 0.07 & 40\% \\\cline{2-6}
    & Dextool & 23 & 255 & 0.08 & N/A \\ \hline
\multirow{3}{*}{\small libgraphqlparser} & Regex & 142 & 15 & 0.90 & 30\% \\\cline{2-6}
    & Comby & 116 & 15 & 0.89 & 20\% \\ \cline{2-6}
    & Dextool & 50 & 2 & 0.96 & N/A \\ \hline
\multirow{3}{*}{\small rethinkdb\_rebirth} & Regex & 65 & 480 & 0.12 & 10\% \\\cline{2-6}
    & Comby & 49 & 443 & 0.10 & 20\% \\ \cline{2-6}
    & Dextool & 9 & 16 & 0.36 & N/A \\ \hline
    
\multirow{3}{*}{\small xoreos} & Regex & 33 & 2386 & 0.01 & 0\% \\\cline{2-6}
    & Comby & 33 & 2247 & 0.01 & 10\% \\ \cline{2-6}
    & Dextool & 8 & 406 & 0.02 & N/A \\ \hline
\multirow{3}{*}{\small libxmljs} & Regex & 547 & 334 & 0.62 & 10\% \\\cline{2-6}
    & Comby & 507 & 283 & 0.64 & 10\% \\ \cline{2-6}
    & Dextool & 383 & 447 & 0.46 & N/A \\ \hline
\multirow{3}{*}{\small tiny-differentiable-simulator} & Regex & 38 & 709 & 0.05 & 0\% \\\cline{2-6}
    & Comby & 32 & 738 & 0.04 & 0\% \\ \cline{2-6}
    & Dextool & 13 & 48 & 0.21 & N/A\\ \hline
    
\multirow{9}{*}{Overall} & \multirow{3}{*}{Regex} & \multicolumn{2}{c|}{Mean} & 0.29  & 13.33\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.09 & 10.00\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.38 & 13.66\% \\\cline{2-6}

 & \multirow{3}{*}{Comby} & \multicolumn{2}{c|}{Mean} & 0.29 & 16.67\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.09 & 15.00\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.37 & 13.66\% \\\cline{2-6}

 & \multirow{3}{*}{Dextool} & \multicolumn{2}{c|}{Mean} & 0.33 & N/A\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.29 & N/A \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.38 & N/A \\ \hline
    
    
\end{tabular}
}
\end{table}

% ---------------- JAVA table (UM vs Others) --------------------------

\begin{table}[htbp]
\centering
\caption{Java (UniversalMutator vs. PIT vs. LittleDarwin)}
\label{tab:table_java2}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|r|r|r|r|}
\hline
 &  & \textbf{Killed} & \textbf{Not Killed} &  \makecell{\textbf{Mutation} \\ \textbf{Score}} & \textbf{Equivalent \%} \\ \hline

 \multirow{4}{*}{\small pebble} & Regex & 70 & 16 & 0.81 & 50\% \\\cline{2-6}
    & Comby & 68 & 17 & 0.80 & 20\% \\\cline{2-6}
    & PIT & 19 & 1 & 0.95 & N/A \\ \cline{2-6}
    & LittleDarwin & 8 & 0 & 1.00 & 0\% \\ \hline
\multirow{4}{*}{\small spring-hateoas} & Regex & 82 & 166 & 0.33 & 0\% \\\cline{2-6}
    & Comby & 65 & 111 & 0.37 & 0\% \\ \cline{2-6}
    & PIT & 82 & 32 & 0.28 & N/A\% \\ \cline{2-6}
    & LittleDarwin & 15 & 23 & 0.39 & 0\% \\ \hline
\multirow{4}{*}{\small javacc} & Regex & 123 & 419 & 0.23 & 0\% \\\cline{2-6}
    & Comby & 103 & 400 & 0.21 & 0\% \\ \cline{2-6}
    & PIT & 30 & 113 & 0.21 & N/A\\ \cline{2-6}
    & LittleDarwin & 64 & 18 & 0.78 & 0\%\\ \hline
\multirow{4}{*}{\small coffee-gb} & Regex & 48 & 176 & 0.21 & 0\%\\\cline{2-6}
    & Comby & 40 & 134 & 0.23 & 0\% \\ \cline{2-6}
    & PIT & 32 & 4 & 0.89 & N/A \\ \cline{2-6}
    & LittleDarwin & 11 & 18 & 0.38 & 0\%\\ \hline
\multirow{4}{*}{\small egads} & Regex & 442 & 182 & 0.71 & 20\% \\\cline{2-6}
    & Comby & 422 & 200 & 0.71 & 10\% \\ \cline{2-6}
    & PIT & 87 & 20 & 0.81 & N/A \\ \cline{2-6}
    & LittleDarwin & 74 & 11 & 0.87 & 0\% \\ \hline
\multirow{4}{*}{\small apk-parser} & Regex & 26 & 325 & 0.07 & 10\%\\\cline{2-6}
    & Comby & 26 & 312 & 0.08 & 0\%\\ \cline{2-6}
    & PIT & 14 & 75  & 0.16 & N/A\\ \cline{2-6}
    & LittleDarwin & 3 & 30 & 0.09 & 0\%\\ \hline
    
\multirow{12}{*}{Overall} & \multirow{3}{*}{Regex} & \multicolumn{2}{c|}{Mean} & 0.39  & 13.33\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.28 & 5.00\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.30 & 19.66\% \\\cline{2-6}

 & \multirow{3}{*}{Comby} & \multicolumn{2}{c|}{Mean} & 0.40 & 5.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.30 & 0.00\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.29 & 8.37\%\\\cline{2-6}

 & \multirow{3}{*}{PIT} & \multicolumn{2}{c|}{Mean} & 0.55 & N/A\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.55 & N/A \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.37 & N/A \\\cline{2-6}
    
 & \multirow{3}{*}{LittleDarwin} & \multicolumn{2}{c|}{Mean} & 0.59 & 0.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.59 & 0.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.35 & 0.00\%\\ \hline
    
\end{tabular}
}
\end{table}

% ----------------  Python table (UM vs Others) -------------------------------

\begin{table}[htbp]
\centering
\caption{Python (UniversalMutator vs. Mutmut vs. CosmicRay)}
\label{tab:table_python2}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|r|r|r|r|}
\hline
 &  & \textbf{Killed} & \textbf{Not Killed} &  \makecell{\textbf{Mutation} \\ \textbf{Score}} & \textbf{Equivalent \%} \\ \hline

 \multirow{4}{*}{\small keract} & Regex & 463 & 1192 & 0.28 & 0\% \\\cline{2-6}
    & Comby & 383 & 1088 & 0.26 & 10\% \\\cline{2-6}
    & Mutmut & 349 & 133 & 0.72 & 10\% \\ \cline{2-6}
    & CosmicRay & 250 & 671 & 0.27 & 10\% \\ \hline
\multirow{3}{*}{\small dtw} & Regex & 506 & 467 & 0.52 & 10\% \\\cline{2-6}
    & Comby & 475 & 391 & 0.55 & 10\% \\ \cline{2-6}
    & Mutmut & 118 & 152 & 0.44 & 0\% \\ \cline{2-6}
    & CosmicRay & 328 & 385 & 0.46 & 20\% \\ \hline
\multirow{3}{*}{\small notion-sdk-py} & Regex & 112 & 84 & 0.57 & 10\% \\\cline{2-6}
    & Comby & 118 & 78 & 0.60 & 20\% \\ \cline{2-6}
    & Mutmut & 41 & 22 & 0.65 & 0\%\\ \cline{2-6}
    & CosmicRay & 23 & 29 & 0.44 & 0\%\\ \hline
    
\multirow{3}{*}{\makecell{\small atlassian-python \\ api}} & Regex & 193 & 109 & 0.64 & 20\%\\\cline{2-6}
    & Comby & 207 & 126 & 0.62 & 40\% \\ \cline{2-6}
    & Mutmut & 123 & 51 & 0.71 & 10\% \\ \cline{2-6}
    & CosmicRay & 78 & 28 & 0.74 & 10\% \\ \hline
\multirow{3}{*}{\small ESD} & Regex & 132 & 1727 & 0.07 & 30\%\\\cline{2-6}
    & Comby & 121 & 1591 & 0.07 & 10\%\\ \cline{2-6}
    & Mutmut & 57 & 663 & 0.08 & 0\%\\ \cline{2-6}
    & CosmicRay & 63 & 950 & 0.06 & 10\%\\ \hline
\multirow{3}{*}{\small fiber} & Regex & 307 & 186 & 0.62 & 10\%\\\cline{2-6}
    & Comby & 291 & 167 & 0.64 & 20\%\\ \cline{2-6}
    & Mutmut & 127 & 95 & 0.57 & 40\%\\ \cline{2-6}
    & CosmicRay & 259 & 61 & 0.81 & 0\%\\ \hline
    
\multirow{12}{*}{Overall} & \multirow{3}{*}{Regex} & \multicolumn{2}{c|}{Mean} & 0.45  & 13.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.55 & 10.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.23 & 10.33\%\\\cline{2-6}

 & \multirow{3}{*}{Comby} & \multicolumn{2}{c|}{Mean} & 0.46 & 18.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.58 & 15.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.24 & 11.69\%\\\cline{2-6}

 & \multirow{3}{*}{Mutmut} & \multicolumn{2}{c|}{Mean} & 0.53 & 10.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.61 & 5.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.24 & 15.49\%\\\cline{2-6}
    
 & \multirow{3}{*}{CosmicRay} & \multicolumn{2}{c|}{Mean} & 0.46 & 8.33\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.45 & 10.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.28 & 7.53\%\\ \hline
    
\end{tabular}
}
\end{table}


% ---------------- Rust table (UM vs Others)--------------------------

\begin{table}[htbp]
\centering
\caption{Rust (UniversalMutator vs. Cargo-Mutants)}
\label{tab:table_rust2}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|r|r|r|r|}
\hline
 &  & \textbf{Killed} & \textbf{Not Killed} &  \makecell{\textbf{Mutation} \\ \textbf{Score}} & \textbf{Equivalent \%} \\ \hline

 \multirow{3}{*}{\small cargo release} & Regex & 721 & 130 & 0.85 & 0\% \\\cline{2-6}
    & Comby & 1344 & 346 & 0.80 & 0\% \\\cline{2-6}
    & Cargo-Mutants & 2	& 3 & 0.40 & 0\% \\ \hline
\multirow{3}{*}{\small passerine} & Regex & 122 & 91 & 0.57 & 20\% \\\cline{2-6}
    & Comby & 90 & 83 & 0.52 & 50\% \\ \cline{2-6}
    & Cargo-Mutants & 0	& 0 & 0 & 0\% \\ \hline
\multirow{3}{*}{\small typos} & Regex & 295 & 91 & 0.76 & 40\% \\\cline{2-6}
    & Comby & 283 & 83 & 0.77 & 20\%\\ \cline{2-6}
    & Cargo-Mutants & 5 & 1 & 0.83 & 0\%\\ \hline
    
\multirow{3}{*}{\small ord} & Regex & 558 & 204 & 0.73 & 10\% \\\cline{2-6}
    & Comby & 533 & 110 & 0.83 & 20\% \\ \cline{2-6}
    & Cargo-Mutants & 6 & 0 & 1.00 & 0\% \\ \hline
\multirow{3}{*}{\small bazuka} & Regex & 281 & 170 & 0.62 & 40\% \\\cline{2-6}
    & Comby & 291 & 111 & 0.73 & 0\% \\ \cline{2-6}
    & Cargo-Mutants & 0 & 0 & 0 & 0\% \\ \hline
\multirow{3}{*}{\small strum} & Regex & 8 & 43 & 0.16 & 10\%\\\cline{2-6}
    & Comby & 11 & 39 & 0.22 & 40\%\\ \cline{2-6}
    & Cargo-Mutants & 2 & 0 & 1.00 & 0\%\\ \hline
    
\multirow{9}{*}{Overall} & \multirow{3}{*}{Regex} & \multicolumn{2}{c|}{Mean} & 0.62  & 20.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.68 & 15.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.24 & 16.73\% \\\cline{2-6}

 & \multirow{3}{*}{Comby} & \multicolumn{2}{c|}{Mean} & 0.64 & 22.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.75 & 20.00\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.25 & 20.41\% \\\cline{2-6}

 & \multirow{3}{*}{Cargo-Mutants} & \multicolumn{2}{c|}{Mean} & 0.54 & 0.00\%\\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Median} & 0.62 & 0.00\% \\\cline{3-6}
    &   &  \multicolumn{2}{c|}{Std. Dev} & 0.47 & 0.00\%\\ \hline
    
    
\end{tabular}
}
\end{table}

\subsection{Haskell Case Study}

\begin{figure}

  \begin{code}
 qsort :: [ Int] -> [ Int ]
 qsort [] = []
 qsort (x: xs ) = qsort l ++ [x] ++ qsort r
     where l = filter (< x) xs
           r = filter ( >= x) xs
\end{code}
\caption{Example from MuCheck Paper}
\label{fig:haskell}

\end{figure}

Figure~\ref{fig:haskell} shows a simple Haskell program, the
motivating example in the paper presenting the MuCheck \cite{mucheck}
mutation testing tool for Haskell.  As noted in the introduction, to our
knowledge MuCheck is the first (and perhaps only) mutation tool for
Haskell code.  MuCheck has not been updated since 2015.
To see how our approach fares when mutating code in a language for
which 1) it has no specific rules and 2) the assumption of a simple
C-like syntax does not hold, we applied our implementation to this example.

Using regular expressions, and only the universal rules, our tool
generates 10 valid mutants and 34 invalid mutants of the code (22.73\%
valid mutants).  Comby produces an identical 10 valid mutants, but 65
invalid mutants (13.33\% validity).  Both tools produce a large number
of invalid mutants here due to including rules such as adding {\tt
  break} and {\tt continue} that are sufficiently widespread in
applicability to be included in our ``universal'' set but do not apply
to Haskell; we believe that comby's awareness of Haskell syntax in
this case actually gives it \emph{more} opportunities to apply such
inapplicable mutants.

These mutants produce a mutation
score of 0.8 for the two properties defined in the original MuCheck
paper.  In other words, like MuCheck, our tool is able to
determine that the properties provided are insufficient.  In
particular, while they check idempotence and that the result is
sorted, they do not check that the result of {\tt qsort} is a permutaton of the input
list.  The MuCheck paper only provides mutation scores for the two
properties independently.  For idempotence, MuCheck gives a mutation
score of 0.84, and our implementation yields a score of 0.8.  Checking
only sortedness, MuCheck yields a score of 0.61, while our approach
produces an even lower score of 0.4.  Our lower
scores are not due to equivalent mutants: adding a property to check
that the sorted list is a permutation of the original list, all
mutants generated by our approach can be killed.

Of course, our implementation does not provide the small set of Haskell-specific
mutations provided by MuCheck (e.g., type-aware function replacement).  It nonetheless produces clearly useful
mutants, even for a language arguably radically different from those
for which the universal rules were developed.  In short, our approach
likely provides users of a new language working, if sub-optimal, mutation testing,
\emph{even if no effort has been expended to define rules for the
  language at all}.

\section{Discussion}

\section{Related Work}

Many approaches have been proposed to tackle the \emph{computational} cost of mutation, including weak-mutation, 
meta-mutation, mutation-sampling, and predicting which mutants will be
killed~\cite{offuttMutant1996,
  untch1993mutation,KaufmanFAKAJ2022,zhang2016pmt}.  Approaches to reducing the cost of
mutation analysis were categorized as \textit{do smarter}, \textit{do
faster}, and \textit{do fewer} by Offutt et al.~\cite{offutt2001mutation}.
The \textit{do smarter} approaches include space-time trade-offs, weak
mutation analysis, and parallelization of mutation analysis. The \textit{do
faster} approaches include mutant schema generation, code patching, and
other methods to make mutants run faster. Finally, the
\textit{do fewer} approaches try to reduce the number of mutants examined,
and include selective mutation and mutant sampling.

None of these approaches focus on the cost in \emph{human} time to
develop and maintain mutation testing tools.  In fact, the complexity
and sophistication of some of these approaches imposes a daunting
barrier to those who would develop ``good'' mutation tools for a new
language.  However, arguably the most powerful and generalizable
methods for reducing the cost of mutation, such as random sampling~\cite{GopinathSampleSize,gopinath2017mutation} and
predictive mutation testing~\cite{zhang2016pmt,kim2022predictive}, are independent of the generation of
mutants and so applicable to any language.

Hariri et al. compared C mutation approaches at the source and
compiler IR levels~\cite{CompareSrcBinary} and found that overall
source level mutation was better, producing fewer mutants overall, but
matching the IR approach in the important measures of surface and
minimal mutants and overall mutation score.  Numerous studies compare
Java mutation tools~\cite{MajorPIT,gopinath2017does}, including a
recent article for a more general audience in Communications of the
ACM~\cite{CommACMJavaTool} (perhaps showing the growing interest in
practical mutation testing).  This paper showed that users
considered active maintenance, support for a variety of testing
frameworks, and support for recent Java versions as the most important
features in a Java mutation tool.  The approach proposed in this paper
by its nature tends to promise all three of these key factors without
imposing onerous burdens on maintainers.

Finally, the practical use of mutation testing at Google argues that
support for a variety of languages is critical, and that the approach
we take is more than sufficient.  Google has used its
substantial resources to provide mutant generation for C++, Java,
Python, Javascript, Go, Typescript, and Common
Lisp~\cite{PetrovicMutationGoogle}, all of which we also support.  The
operators Google uses for these
languages (based on the original Mothra operators~\cite{offutt1996experimental}) are a subset of those provided by our implementation, with the caveat
that statement block removal is only supported when using Comby;
regular expression mutation is limited to single-line statement
deletion.  For Lisp-like languages, the difficulty of identifying statements vs. value-returning
function calls makes use of block deletion somewhat impractical, but
still easy to implement.  The majority of the Google Mothra operators
can be implemented in
a few lines as universal rules for all languages; only specializing
logical operators and implementing block/statement deletion even requires
language identification.  Unlike Google's mutation infrastructure, our
tool is open source, easily extensible, and not tied to any particular
development environment.

The approach reported in this paper was briefly presented in part in a
tool paper (citation redacted for blinding purposes) that introduced
the idea of using regular expressions to generate mutants for multiple
languages, and provided an evaluation against PIT for a single toy
Java program.  The present paper provides the full idea and context,
provides empirical data for universal mutant generation on real world
programs over four languages,
and introduces the idea of using parser parser combinators to improve
on regular expression-based generation.

\section{Conclusions and Future Work}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}


\end{document}
