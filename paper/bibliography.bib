
@inproceedings{ThierryStudy,
  author={Chekam, Thierry Titcheu and Papadakis, Mike and Le Traon, Yves and Harman, Mark},
  booktitle={International Conference on Software Engineering}, 
  title={An Empirical Study on Mutation, Statement and Branch Coverage Fault Revelation That Avoids the Unreliable Clean Program Assumption}, 
  year={2017},
  volume={},
  number={},
  pages={597-608},
  doi={10.1109/ICSE.2017.61}
}

@misc{buterin2013whitepaper,
  author = {Vitalik Buterin},
  title = {Ethereum: A Next-Generation Smart Contract and Decentralized Application Platform},
  howpublished = "\url{https://github.com/ethereum/wiki/wiki/White-Paper}",
  year = {2013}
}

@misc{vsbenchmark,
title = "{VeriSmart} benchmark",
  howpublished={\url{https://github.com/kupl/VeriSmart-benchmarks}}
  }

@article{wodeltest,
author = {G\'{o}mez-Abajo, Pablo and Guerra, Esther and Lara, Juan de and Merayo, Mercedes G.},
title = {Wodel-Test: A Model-Based Framework for Language-Independent Mutation Testing},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00827-0},
doi = {10.1007/s10270-020-00827-0},
abstract = {Mutation testing (MT) targets the assessment of test cases by measuring their efficiency to detect faults. This technique involves modifying the program under test to emulate programming faults, and assessing whether the existing test cases detect such mutations. MT has been extensively studied since the 70’s, and many tools have been proposed for widely used languages like C, Java, Fortran, Ada and SQL; and for notations like Petri-nets. However, building MT tools is costly and error-prone, which may prevent their development for new programming and domain-specific (modelling) languages. In this paper, we propose a framework called Wodel-Test to reduce the effort to create MT tools. For this purpose, it follows a model-driven approach by which MT tools are synthesized from a high-level description. This description makes use of the domain-specific language Wodel to define and execute model mutations. Wodel is language-independent, as it allows the creation of mutation operators for any language defined by a meta-model. Starting from the definition of the mutation operators, Wodel-Test generates a MT environment which parses the program under test into a model, applies the mutation operators, and evaluates the test-suite against the generated mutants, offering a rich collection of MT metrics. We report on an evaluation of the approach based on the creation of MT tools for Java and the Atlas transformation language.},
journal = {Softw. Syst. Model.},
month = {jun},
pages = {767–793},
numpages = {27},
keywords = {Model-driven engineering, Model transformation, Domain-specific languages, Mutation testing, Java, Model mutation}
}

@INPROCEEDINGS{GoogleMut,
  author={Petrovic, Goran and Ivankovic, Marko and Kurtz, Bob and Ammann, Paul and Just, René},
  booktitle={2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={An Industrial Application of Mutation Testing: Lessons, Challenges, and Research Directions}, 
  year={2018},
  volume={},
  number={},
  pages={47-53},
  doi={10.1109/ICSTW.2018.00027}}

@inproceedings{flaky,
author = {Eck, Moritz and Palomba, Fabio and Castelluccio, Marco and Bacchelli, Alberto},
title = {Understanding Flaky Tests: The Developer’s Perspective},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338945},
doi = {10.1145/3338906.3338945},
abstract = {Flaky tests are software tests that exhibit a seemingly random outcome (pass or fail)
despite exercising unchanged code. In this work, we examine the perceptions of software
developers about the nature, relevance, and challenges of flaky tests. We asked 21
professional developers to classify 200 flaky tests they previously fixed, in terms
of the nature and the origin of the flakiness, as well as of the fixing effort. We
also examined developers' fixing strategies. Subsequently, we conducted an online
survey with 121 developers with a median industrial programming experience of five
years. Our research shows that: The flakiness is due to several different causes,
four of which have never been reported before, despite being the most costly to fix;
flakiness is perceived as significant by the vast majority of developers, regardless
of their team's size and project's domain, and it can have effects on resource allocation,
scheduling, and the perceived reliability of the test suite; and the challenges developers
report to face regard mostly the reproduction of the flaky behavior and the identification
of the cause for the flakiness. Public preprint [http://arxiv.org/abs/1907.01466],
data and materials [https://doi.org/10.5281/zenodo.3265785].},
booktitle = {Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {830–840},
numpages = {11},
keywords = {Mixed-Method Research, Flaky Tests, Empirical Studies},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}



@inproceedings{fuzzexp,
author = {B\"{o}hme, Marcel and Falk, Brandon},
title = {Fuzzing: On the Exponential Cost of Vulnerability Discovery},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409729},
doi = {10.1145/3368089.3409729},
abstract = {We present counterintuitive results for the scalability of fuzzing. Given the same
non-deterministic fuzzer, finding the same bugs linearly faster requires linearly
more machines. For instance, with twice the machines, we can find all known bugs in
half the time. Yet, finding linearly more bugs in the same time requires exponentially
more machines. For instance, for every new bug we want to find in 24 hours, we might
need twice more machines. Similarly for coverage. With exponentially more machines,
we can cover the same code exponentially faster, but uncovered code only linearly
faster. In other words, re-discovering the same vulnerabilities is cheap but finding
new vulnerabilities is expensive. This holds even under the simplifying assumption
of no parallelization overhead. We derive these observations from over four CPU years
worth of fuzzing campaigns involving almost three hundred open source programs, two
state-of-the-art greybox fuzzers, four measures of code coverage, and two measures
of vulnerability discovery. We provide a probabilistic analysis and conduct simulation
experiments to explain this phenomenon.},
booktitle = {Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {713–724},
numpages = {12},
keywords = {scalability, software testing, efficiency, fuzzing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}



@inproceedings{echidnaissta,
author = {Grieco, Gustavo and Song, Will and Cygan, Artur and Feist, Josselin and Groce, Alex},
title = {Echidna: Effective, Usable, and Fast Fuzzing for Smart Contracts},
year = {2020},
address = {New York, NY, USA},
booktitle = {International Symposium on Software Testing and Analysis},
pages = {557–560}
}



@inproceedings{verismart,
    title={{VeriSmart}: A Highly Precise Safety Verifier for Ethereum Smart Contracts},
    author={Sunbeom So and Myungho Lee and Jisu Park and Heejo Lee and Hakjoo Oh},
    year={2020},
   booktitle={Symposium on Security \& Privacy},
   notes = {accepted for publication}
}

@misc{measurepop,
  howpublished="\url{https://github.com/smartanvil/smartanvil.github.io/blob/master/_posts/2018-03-14-on-contract-popularity-analysis.md}",
  title="On Contract Popularity Analysis",
  author="Santiago Bragagnolo"
}

@techreport{smartanvil,
  title={SmartAnvil: Open-Source Tool Suite for Smart Contract Analysis},
  author={Ducasse, St{\'e}phane and Rocha, Henrique and Bragagnolo, Santiago and Denker, Marcus and Francomme, Cl{\'e}ment},
  year={2019},
  institution="{HAL}",
  number="hal-01940287"
}

@mastersthesis{dika2017ethereum,
  title={Ethereum Smart Contracts: Security Vulnerabilities and Security Tools},
  author={Dika, Ardit},
  year={2017},
  school={NTNU}
}

@inproceedings{chen2018under,
 author = {Chen, Ting and Li, Zihao and Zhou, Hao and Chen, Jiachi and Luo, Xiapu and Li, Xiaoqi and Zhang, Xiaosong},
 title = {Towards Saving Money in Using Smart Contracts},
 booktitle = {International Conference on Software Engineering: New Ideas and Emerging Results},
 series = {ICSE-NIER 2018},
 year = {2018},
 isbn = {978-1-4503-5662-6},
 location = {Gothenburg, Sweden},
 pages = {81--84},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3183399.3183420},
 doi = {10.1145/3183399.3183420},
 acmid = {3183420},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {anti-patterns, detection, optimization, smart contract},
} 

@inproceedings{chen2017under,
  title={Under-optimized smart contracts devour your money},
  author={Chen, Ting and Li, Xiaoqi and Luo, Xiapu and Zhang, Xiaosong},
  booktitle={Software Analysis, Evolution and Reengineering},
  pages={442--446},
  year={2017},
  organization={IEEE}
}

@misc{wood2014yellow,
  author = {Gavin Wood},
  title = {Ethereum:  a  secure  decentralised  generalised  transaction  ledger},
  howpublished = "\url{http://gavwood.com/paper.pdf}",
  year = {2014}
}

@misc{nakamoto2008bitcoin,
  title={Bitcoin: A peer-to-peer electronic cash system},
  author={Satoshi Nakamoto},
  howpublished = "\url{https://bitcoin.org/bitcoin.pdf}",
  year={2008}
}

@inproceedings{slitherpaper,
  author = "Josselin Feist and Gustavo Greico and Alex Groce",
  title = "Slither: A Static Analysis Framework For Smart Contracts",
  year = 2019,
  booktitle = "International Workshop on Emerging Trends in Software Engineering for Blockchain",
  }

@misc{parity,
  title={Parity Ethereum client},
  author={Parity},
  howpublished = "\url{https://parity.io}",
  year={2016}
}

@misc{special,
  title={Journal Special Issue on Fuzzing:
What about Preregistration?},
  author={Marcel B\"{o}hme and L\'{a}szl\'{o} Szekeres and Baishakhi Ray and Cristian Cadar},
  howpublished={\url{http://fuzzbench.com/blog/2021/04/22/special-issue/}},
  year={2021},
  month={April}}


@inproceedings{evalfuzz,
author = {Klees, George and Ruef, Andrew and Cooper, Benji and Wei, Shiyi and Hicks, Michael},
title = {Evaluating Fuzz Testing},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243804},
doi = {10.1145/3243734.3243804},
abstract = {Fuzz testing has enjoyed great success at discovering security critical bugs in real
software. Recently, researchers have devoted significant effort to devising new fuzzing
techniques, strategies, and algorithms. Such new ideas are primarily evaluated experimentally
so an important question is: What experimental setup is needed to produce trustworthy
results? We surveyed the recent research literature and assessed the experimental
evaluations carried out by 32 fuzzing papers. We found problems in every evaluation
we considered. We then performed our own extensive experimental evaluation using an
existing fuzzer. Our results showed that the general problems we found in existing
experimental evaluations can indeed translate to actual wrong or misleading assessments.
We conclude with some guidelines that we hope will help improve experimental evaluations
of fuzz testing algorithms, making reported results more robust.},
booktitle = {Conference on Computer and Communications Security},
pages = {2123–2138},
numpages = {16},
keywords = {security, evaluation, fuzzing},
location = {Toronto, Canada},
series = {CCS 2018}
}


@article{buddEquivalent,
  author    = {Timothy A. Budd and
               Dana Angluin},
  title     = {Two Notions of Correctness and Their Relation to Testing},
  journal   = {Acta Informatica},
  volume    = {18},
  pages     = {31--45},
  year      = {1982},
  url       = {https://doi.org/10.1007/BF00625279},
  doi       = {10.1007/BF00625279},
  timestamp = {Sun, 21 Jun 2020 17:38:20 +0200},
  biburl    = {https://dblp.org/rec/journals/acta/BuddA82.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{testedness,
author = {Ahmed, Iftekhar and Gopinath, Rahul and Brindescu, Caius and Groce, Alex and Jensen, Carlos},
title = {Can Testedness Be Effectively Measured?},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2950290.2950324},
doi = {10.1145/2950290.2950324},
abstract = { Among the major questions that a practicing tester faces are deciding where to focus
additional testing effort, and deciding when to stop testing. Test the least-tested
code, and stop when all code is well-tested, is a reasonable answer. Many measures
of "testedness" have been proposed; unfortunately, we do not know whether these are
truly effective. In this paper we propose a novel evaluation of two of the most important
and widely-used measures of test suite quality. The first measure is statement coverage,
the simplest and best-known code coverage measure. The second measure is mutation
score, a supposedly more powerful, though expensive, measure. We evaluate these measures
using the actual criteria of interest: if a program element is (by these measures)
well tested at a given point in time, it should require fewer future bug-fixes than
a "poorly tested" element. If not, then it seems likely that we are not effectively
measuring testedness. Using a large number of open source Java programs from Github
and Apache, we show that both statement coverage and mutation score have only a weak
negative correlation with bug-fixes. Despite the lack of strong correlation, there
are statistically and practically significant differences between program elements
for various binary criteria. Program elements (other than classes) covered by any
test case see about half as many bug-fixes as those not covered, and a similar line
can be drawn for mutation score thresholds. Our results have important implications
for both software engineering practice and research evaluation. },
booktitle = {International Symposium on Foundations of Software Engineering},
pages = {547–558},
numpages = {12},
keywords = {coverage criteria, statistical analysis, mutation testing, test suite evaluation},
location = {Seattle, WA, USA},
series = {FSE 2016}
}



@article{HolmesLOC,
author = {Holmes, Josie and Ahmed, Iftekhar and Brindescu, Caius and Gopinath, Rahul and Zhang, He and Groce, Alex},
title = {Using Relative Lines of Code to Guide Automated Test Generation for Python},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3408896},
doi = {10.1145/3408896},
abstract = {Raw lines of code (LOC) is a metric that does not, at first glance, seem extremely useful for automated test generation. It is both highly language-dependent and not extremely meaningful, semantically, within a language: one coder can produce the same effect with many fewer lines than another. However, relative LOC, between components of the same project, turns out to be a highly useful metric for automated testing. In this article, we make use of a heuristic based on LOC counts for tested functions to dramatically improve the effectiveness of automated test generation. This approach is particularly valuable in languages where collecting code coverage data to guide testing has a very high overhead. We apply the heuristic to property-based Python testing using the TSTL (Template Scripting Testing Language) tool. In our experiments, the simple LOC heuristic can improve branch and statement coverage by large margins (often more than 20%, up to 40% or more) and improve fault detection by an even larger margin (usually more than 75% and up to 400% or more). The LOC heuristic is also easy to combine with other approaches and is comparable to, and possibly more effective than, two well-established approaches for guiding random testing.},
journal = {Transactions on Software Engineering and Methodology},
month = sep,
articleno = {28},
numpages = {38},
keywords = {Automated test generation, static code metrics, testing heuristics}
}

@misc{slither-code,
  title={Slither: a static analyzer for Solidity},
  author={{Anonymized for review}},
  howpublished = "{Anonymized for review}",
  year={2018}
}


%  title={Slither: a static analyzer for Solidity},
%  author={{Trail of Bits}},
%  howpublished = "\url{https://github.com/trailofbits/slither}",
%  year={2018}
%}



@misc{slither-api,
  title={{Slither Python API}},
  author={{Trail of Bits}},
  howpublished = "\url{https://github.com/trailofbits/slither/wiki/API-examples}",
  year={2018}
}


@misc{slither-slithir,
  title={SlithIR Documentation},
  author={{Trail of Bits}},
  howpublished = "\url{https://github.com/trailofbits/slither/wiki/SlithIR}",
  year={2018}
}




@misc{spank,
  title={We Got Spanked: What We Know So Far},
  author={{SpankChain}},
  howpublished = "\url{https://medium.com/spankchain/we-got-spanked-what-we-know-so-far-d5ed3a0f38fe}",
  year={Oct 8, 2018 (acceded on Jan 10, 2019)}
}

@inproceedings{SurveyAttacks,
 author = {Atzei, Nicola and Bartoletti, Massimo and Cimoli, Tiziana},
 title = {A Survey of Attacks on {Ethereum} Smart Contracts {SoK}},
 booktitle = {International Conference on Principles of Security and Trust},
 year = {2017},
 pages = {164--186},
 url = {https://doi.org/10.1007/978-3-662-54455-6_8},
 doi = {10.1007/978-3-662-54455-6_8}
} 

@misc{reports,
  title={Trail of Bits Security Reviews},
  author = {{Trail of Bits}},
  howpublished="\url{https://github.com/trailofbits/publications\#security-reviews}",
  year=2019
  }

@misc{DAO,
  title={Analysis of the DAO exploit},
  author={{Phil Daian }},
  howpublished = "\url{http://hackingdistributed.com/2016/06/18/analysis-of-the-dao-exploit/}",
  year={June 18, 2016 (acceded on Jan 10, 2019)}
}

@misc{echidna-code,
  title={Echidna: Ethereum fuzz testing framework},
  author={{Trail of Bits}},
  howpublished = "\url{https://github.com/trailofbits/echidna}",
  year={2018}
}

@misc{mythril-code,
  title={Mythril: a security analysis tool for Ethereum smart contracts},
  author={ConsenSys},
  howpublished = "\url{https://github.com/ConsenSys/mythril-classic}",
  year={2017}
}

@misc{manticore-code,
  title={Manticore: Symbolic Execution for Humans},
  author={{Trail of Bits}},
  howpublished="\url{https://github.com/trailofbits/manticore}",
  year={2017}
}

@misc{mythx,
  howpublished="\url{https://mythx.io/}",
  author="Consensys Diligence",
  }

@misc{solhint-code,
  title={Solhint: an open source project for linting solidity code},
  author={Protofire},
  howpublished = "\url{https://protofire.github.io/solhint/}",
  year={2017}
}

@misc{oyente-code,
  title={Oyente: an analysis tool for smart contracts},
  author={Melon Project},
  howpublished = "\url{https://github.com/melonproject/oyente}",
  year={2017}
}


@misc{etherscan,
  title={Verified contracts synced from Etherscan},
  author={Gerhard Wagner},
  howpublished = "\url{https://github.com/thec00n/etherscan_verified_contracts}",
  year={2018}
}

@misc{aflfuzz,
  title = "american fuzzy lop (2.35b)",
  author = "Michal Zalewski",
  howpublished = "\url{http://lcamtuf.coredump.cx/afl/}",
  note = "Accessed December 20, 2016"
}

@inproceedings{ClaessenH00,
author    = {Koen Claessen and
           John Hughes},
title     = {{QuickCheck}: a lightweight tool for random testing of {Haskell}
           programs},
booktitle = {International Conference on Functional Programming {(ICFP)}},
year      = {2000},
pages     = {268--279},
ee        = {http://doi.acm.org/10.1145/351240.351266},
bibsource = {DBLP, http://dblp.uni-trier.de}
}


@inproceedings{icseseip22,
  author={Alex Groce and Kush Jain and Rijnard van Tonder and Goutamkumar Tulajappa Kalburgi and Claire {Le~Goues}},
  booktitle={International Conference on Software Engineering:
               Software Engineering in Practice}, 
  title={Looking for Lacunae in Bitcoin Core’s Fuzzing Efforts}, 
  year={2022},
  volume={},
  number={},
  pages={},
  doi={}}

@article{kintisEquivalenceCompilerOptimization,
  author={Kintis, Marinos and Papadakis, Mike and Jia, Yue and Malevris, Nicos and Le Traon, Yves and Harman, Mark},
  journal={IEEE Transactions on Software Engineering}, 
  title={Detecting Trivial Mutant Equivalences via Compiler Optimisations}, 
  year={2018},
  volume={44},
  number={4},
  pages={308-333},
  doi={10.1109/TSE.2017.2684805}}

@misc{AmazonMut,
  author="Giorgio Natili",
  title="Mutation Testing at Scale",
  howpublished="\url{https://slides.com/giorgionatili/mutation-testing-at-scale}"
  }

@book{mathur2012foundations,
  author = {Mathur, Aditya P},
  title = {Foundations of Software Testing},
  year = {2012},
  publisher = {Addison-Wesley}
}

@inproceedings{mucheck,
author = {Le, Duc and Alipour, Mohammad Amin and Gopinath, Rahul and Groce, Alex},
title = {MuCheck: An Extensible Tool for Mutation Testing of Haskell Programs},
year = {2014},
isbn = {9781450326452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2610384.2628052},
doi = {10.1145/2610384.2628052},
abstract = {This paper presents MuCheck, a mutation testing tool for Haskell programs. MuCheck is a counterpart to the widely used QuickCheck random testing tool for functional programs, and can be used to evaluate the efficacy of QuickCheck property definitions. The tool implements mutation operators that are specifically designed for functional programs, and makes use of the type system of Haskell to achieve a more relevant set of mutants than otherwise possible. Mutation coverage is particularly valuable for functional programs due to highly compact code, referential transparency, and clean semantics; these make augmenting a test suite or specification based on surviving mutants a practical method for improved testing.},
booktitle = {Proceedings of the 2014 International Symposium on Software Testing and Analysis},
pages = {429–432},
numpages = {4},
keywords = {Mutation Operators, Haskell, Mutatation Testing, Functional Programming Languages},
location = {San Jose, CA, USA},
series = {ISSTA 2014}
}

@inproceedings{FitSpec,
author = {Braquehais, Rudy and Runciman, Colin},
title = {FitSpec: Refining Property Sets for Functional Testing},
year = {2016},
isbn = {9781450344340},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976002.2976003},
doi = {10.1145/2976002.2976003},
abstract = {This paper presents FitSpec, a tool providing automated assistance in the task of refining sets of test properties for Haskell functions. FitSpec tests mutant variations of functions under test against a given property set, recording any surviving mutants that pass all tests. The number of surviving mutants and any smallest survivor are presented to the user. A surviving mutant indicates incompleteness of the property set, prompting the user to amend a property or to add a new one, making the property set stronger. Based on the same test results, FitSpec also provides conjectures in the form of equivalences and implications between property subsets. These conjectures help the user to identify minimal core subsets of properties and so to reduce the cost of future property-based testing.},
booktitle = {Proceedings of the 9th International Symposium on Haskell},
pages = {1–12},
numpages = {12},
keywords = {formal specification, Haskell, property-based testing, mutation testing, systematic testing},
location = {Nara, Japan},
series = {Haskell 2016}
}

@inproceedings{TCE,
  author = "Mike Papadakis and Yue Jia and Mark Harman and Yves Le Traon",
  title = "Trivial Compiler Equivalence: A Large Scale Empirical Study of a Simple Fast and Effective Equivalent Mutant Detection Technique",
  booktitle = "International Conference on Software Engineering",
  year = 2015
  }


@book{ammann2016introduction,
  title={Introduction to software testing},
  author={Ammann, Paul and Offutt, Jeff},
  year={2016},
  publisher={Cambridge University Press}
}

@inproceedings{BellerFacebookMutation,
  author    = {Moritz Beller and
               Chu{-}Pan Wong and
               Johannes Bader and
               Andrew Scott and
               Mateusz Machalica and
               Satish Chandra and
               Erik Meijer},
  title     = {What It Would Take to Use Mutation Testing in Industry - {A} Study
               at Facebook},
  booktitle = {International Conference on Software Engineering:
               Software Engineering in Practice},
  pages     = {268--277},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00036},
  doi       = {10.1109/ICSE-SEIP52600.2021.00036},
  timestamp = {Mon, 28 Jun 2021 14:32:57 +0200},
  biburl    = {https://dblp.org/rec/conf/icse/BellerWBSM0021.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{papadakis2018mutation,
  title={Are mutation scores correlated with real fault detection? a large scale empirical study on the relationship between mutants and real faults},
  author={Papadakis, Mike and Shin, Donghwan and Yoo, Shin and Bae, Doo-Hwan},
  booktitle={International Conference on Software Engineering},
  pages={537--548},
  year={2018},
  organization={IEEE}
}

@article{offutt1996experimental,
  title={An experimental determination of sufficient mutant operators},
  author={Offutt, A Jefferson and Lee, Ammei and Rothermel, Gregg and Untch, Roland H and Zapf, Christian},
  journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume={5},
  number={2},
  pages={99--118},
  year={1996},
  publisher={ACM New York, NY, USA}
}

@inproceedings{PetrovicMutationGoogle,
  author    = {Goran Petrovic and
               Marko Ivankovic},
  editor    = {Frances Paulisch and
               Jan Bosch},
  title     = {State of mutation testing at google},
  booktitle = {International Conference on Software Engineering:
               Software Engineering in Practice},
  pages     = {163--171},
  publisher = {{ACM}},
  year      = {2018},
  url       = {https://doi.org/10.1145/3183519.3183521},
  doi       = {10.1145/3183519.3183521},
  timestamp = {Tue, 10 Aug 2021 14:29:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icse/PetrovicI18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{jia2008constructing,
  title={Constructing subtle faults using higher order mutation testing},
  author={Jia, Yue and Harman, Mark},
  booktitle={International Working Conference on Source Code Analysis and Manipulation},
  pages={249--258},
  year={2008},
  organization={IEEE}
}

@INPROCEEDINGS{Limits,
  author={Gopinath, Rahul and Alipour, Mohammad Amin and Ahmed, Iftekhar and Jensen, Carlos and Groce, Alex},
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)}, 
  title={On The Limits of Mutation Reduction Strategies}, 
  year={2016},
  volume={},
  number={},
  pages={511-522},
  doi={}}


@inproceedings{zhangPMT,
author = {Zhang, Jie and Wang, Ziyi and Zhang, Lingming and Hao, Dan and Zang, Lei and Cheng, Shiyang and Zhang, Lu},
title = {Predictive Mutation Testing},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2931038},
doi = {10.1145/2931037.2931038},
abstract = { Mutation testing is a powerful methodology for evaluating test suite quality. In mutation testing, a large number of mutants are generated and executed against the test suite to check the ratio of killed mutants. Therefore, mutation testing is widely believed to be a computationally expensive technique. To alleviate the efficiency concern of mutation testing, in this paper, we propose predictive mutation testing (PMT), the first approach to predicting mutation testing results without mutant execution. In particular, the proposed approach constructs a classification model based on a series of features related to mutants and tests, and uses the classification model to predict whether a mutant is killed or survived without executing it. PMT has been evaluated on 163 real-world projects under two application scenarios (i.e., cross-version and cross-project). The experimental results demonstrate that PMT improves the efficiency of mutation testing by up to 151.4X while incurring only a small accuracy loss when predicting mutant execution results, indicating a good tradeoff between efficiency and effectiveness of mutation testing. },
booktitle = {International Symposium on Software Testing and Analysis},
pages = {342–353},
numpages = {12},
keywords = {software testing, mutation testing, machine learning},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}

@inproceedings{PapadakisStudy,
  author    = {Mike Papadakis and
               Nicos Malevris},
  title     = {An Empirical Evaluation of the First and Second Order Mutation Testing
               Strategies},
  booktitle = {International Conference on Software Testing, Verification and
               Validation},
  pages     = {90--99},
  publisher = {{IEEE} Computer Society},
  year      = {2010},
  url       = {https://doi.org/10.1109/ICSTW.2010.50},
  doi       = {10.1109/ICSTW.2010.50},
  timestamp = {Thu, 14 Oct 2021 10:22:07 +0200},
  biburl    = {https://dblp.org/rec/conf/icst/PapadakisM10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@inproceedings{SmithCoverageMutation,
  author={Smith, Ben H. and Williams, Laurie},
  booktitle={Testing: Academic and Industrial Conference Practice and Research Techniques}, 
  title={An Empirical Evaluation of the MuJava Mutation Operators}, 
  year={2007},
  volume={},
  number={},
  pages={193-202},
  doi={10.1109/TAIC.PART.2007.12}}

@inproceedings{LiCoverageMutation,
  author={Li, Nan and Praphamontripong, Upsorn and Offutt, Jeff},
  booktitle={International Conference on Software Testing, Verification, and Validation Workshops}, 
  title={An Experimental Comparison of Four Unit Test Criteria: Mutation, Edge-Pair, All-Uses and Prime Path Coverage}, 
  year={2009},
  volume={},
  number={},
  pages={220-229},
  doi={10.1109/ICSTW.2009.30}}

@inproceedings{JustMutationFault,
   author = {Ren{\'e} Just and Darioush Jalali and Laura Inozemtseva and
	Michael D. Ernst and Reid Holmes and Gordon Fraser},
   title = {Are mutants a valid substitute for real faults in software
	testing?},
   booktitle = {Symposium on the Foundations of
	Software Engineering},
   pages = {654--665},
   address = {Hong Kong},
   month = {November~18--20},
   year = {2014},
}

@inproceedings{StaatsOracle,
  author    = {Matt Staats and
               Michael W. Whalen and
               Mats Per Erik Heimdahl},
  editor    = {Richard N. Taylor and
               Harald C. Gall and
               Nenad Medvidovic},
  title     = {Programs, tests, and oracles: the foundations of testing revisited},
  booktitle = {International Conference on Software Engineering},
  pages     = {391--400},
  publisher = {{ACM}},
  year      = {2011},
  url       = {https://doi.org/10.1145/1985793.1985847},
  doi       = {10.1145/1985793.1985847},
  timestamp = {Tue, 06 Nov 2018 11:06:55 +0100},
  biburl    = {https://dblp.org/rec/conf/icse/StaatsWH11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ZellerCheckedCov,
  author    = {David Schuler and
               Andreas Zeller},
  title     = {Assessing Oracle Quality with Checked Coverage},
  booktitle = {International Conference on Software Testing, Verification
               and Validation},
  pages     = {90--99},
  publisher = {{IEEE} Computer Society},
  year      = {2011},
  url       = {https://doi.org/10.1109/ICST.2011.32},
  doi       = {10.1109/ICST.2011.32},
  timestamp = {Sun, 25 Jul 2021 11:49:18 +0200},
  biburl    = {https://dblp.org/rec/conf/icst/SchulerZ11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{EquivMut,
author = {Schuler, David and Zeller, Andreas},
title = {Covering and Uncovering Equivalent Mutants},
journal = {Software Testing, Verification and Reliability},
volume = {23},
number = {5},
pages = {353-374},
keywords = {mutation testing, code coverage, dynamic analysis},
doi = {https://doi.org/10.1002/stvr.1473},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1473},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/stvr.1473},
abstract = {SUMMARYMutation testing measures the adequacy of a test suite by seeding artificial defects (mutations) into a program. If a test suite fails to detect a mutation, it may also fail to detect real defects—and hence should be improved. However, there are also mutations that keep the program semantics unchanged and thus cannot be detected by any test suite. Such equivalent mutants must be weeded out manually, which is a tedious task. In this paper, we examine whether changes in coverage can be used to detect non-equivalent mutants: If a mutant changes the coverage of a run, it is more likely to be non-equivalent. In a sample of 140 manually classified mutations of seven Java programs with 5000 to 100 000 lines of code, we found that (i) the problem is serious and widespread—about 45\% of all undetected mutants turned out to be equivalent; (ii) manual classification takes time—about 15 min per mutation; (iii) coverage is a simple, efficient and effective means to identify equivalent mutants—with a classification precision of 75\% and a recall of 56\%; and (iv) coverage as an equivalence detector is superior to the state of the art, in particular violations of dynamic invariants. Our detectors have been released as part of the open-source JAVALANCHE framework; the data set is publicly available for replication and extension of experiments. Copyright © 2012 John Wiley \& Sons, Ltd.},
year = {2013}
}



@INPROCEEDINGS{DoGenerated,
  author={Shamshiri, Sina and Just, René and Rojas, José Miguel and Fraser, Gordon and McMinn, Phil and Arcuri, Andrea},
  booktitle={International Conference on Automated Software Engineering}, 
  title={Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges (T)}, 
  year={2015},
  volume={},
  number={},
  pages={201-211},
  doi={10.1109/ASE.2015.86}}

@article{HintsOnTestDataSelection,
author={R. A. {DeMillo} and R. J. {Lipton} and F. G. {Sayward}},
journal={Computer},
title={Hints on Test Data Selection: Help for the Practicing Programmer},
year={1978},
volume={11},
number={4},
pages={34-41},
doi={10.1109/C-M.1978.218136},
ISSN={0018-9162},
month={April},
}

@book{LessonsLearned,
author = {Kaner, Cem and Bach, James and Pettichord, Bret},
title = {Lessons Learned in Software Testing},
year = {2001},
isbn = {0471081124},
publisher = {John Wiley and Sons, Inc.},
address = {USA},
abstract = {From the Publisher: Great software testing teams aren't born, they're made-through a lot of hard work and persuasive communication. Along the way, there is an abundance of traps that one can fall into, which can derail the best-laid plans and put your projects behind schedule. Cem Kaner, James Bach, and Bret Pettichord know this all too well. Between them, they have over fifty years of testing experience, and know what it takes for successful testing. In this groundbreaking new book, they have compiled 293 pieces of experience-tested advice for you to put to work in your testing projects. They reveal insights on how to do the job well, how to manage it, and how to steer clear of common misunderstandings in software testing. Each lesson is an assertion related to software testing, followed by an explanation or example that shows you the how, when, and why of the testing lesson. The ultimate resource for software testers, developers, and managers at every level of expertise, this guidebook also features: Useful practices and helpful ways of evaluating situations gleaned from over fifty years of combined testing experience from the world's leading software testing experts Lessons for all key topic areas including test design, test automation, test management, testing strategies, and bug reporting Advice on how to match the selection of practices to the circumstances of your project Wiley Computer Publishing Timely. Practical. Reliable. Author Biography: CEM KANER, JD, PhD, is a professor of computer sciences at Florida Institute of Technology. He also consults on technical and management issues, and practices law within the software development community. He is the lead author of two books, Testing Computer Software and Bad Software (both from Wiley). JAMES BACH is founder and principal consultant of Satisfice, Inc., a software testing and quality assurance company. His experience with competitive software development in leading Silicon Valley companies, such as Apple and Borland, led him to specialize in such aspects of the craft as "good enough" quality, risk-based testing, exploratory testing, and other techniques that require skill and judgment. He has also served as Chief Scientist at Software Testing Labs. BRET PETTICHORD works as an independent consultant and edits the popular Software Testing Hotlist. A frequent speaker and writer, he is also the founder of the Austin Workshop on Test Automation.}
}

@misc{whatdoweknow,
  doi = {10.48550/ARXIV.2204.09165},
  
  url = {https://arxiv.org/abs/2204.09165},
  
  author = {Zhang, Peng and Wang, Yang and Liu, Xutong and Yang, Yibiao and Li, Yanhui and Chen, Lin and Wang, Ziyuan and Sun, Chang-ai and Zhou, Yuming},
  
  keywords = {Software Engineering (cs.SE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Test suite effectiveness metric evaluation: what do we know and what should we do?},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@inproceedings{inozemtsevaCoverageTestEffectiveness,
author = {Inozemtseva, Laura and Holmes, Reid},
title = {Coverage is Not Strongly Correlated with Test Suite Effectiveness},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568271},
doi = {10.1145/2568225.2568271},
abstract = { The coverage of a test suite is often used as a proxy for its ability to detect faults. However, previous studies that investigated the correlation between code coverage and test suite effectiveness have failed to reach a consensus about the nature and strength of the relationship between these test suite characteristics. Moreover, many of the studies were done with small or synthetic programs, making it unclear whether their results generalize to larger programs, and some of the studies did not account for the confounding influence of test suite size. In addition, most of the studies were done with adequate suites, which are are rare in practice, so the results may not generalize to typical test suites. We have extended these studies by evaluating the relationship between test suite size, coverage, and effectiveness for large Java programs. Our study is the largest to date in the literature: we generated 31,000 test suites for five systems consisting of up to 724,000 lines of source code. We measured the statement coverage, decision coverage, and modified condition coverage of these suites and used mutation testing to evaluate their fault detection effectiveness. We found that there is a low to moderate correlation between coverage and effectiveness when the number of test cases in the suite is controlled for. In addition, we found that stronger forms of coverage do not provide greater insight into the effectiveness of the suite. Our results suggest that coverage, while useful for identifying under-tested parts of a program, should not be used as a quality target because it is not a good indicator of test suite effectiveness. },
booktitle = {International Conference on Software Engineering},
pages = {435–445},
numpages = {11},
keywords = {test suite effectiveness, Coverage, test suite quality},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@article{pizzoleto2019systematic,
  title={A systematic literature review of techniques and metrics to reduce the cost of mutation testing},
  author={Pizzoleto, Alessandro Viola and Ferrari, Fabiano Cutigi and Offutt, Jeff and Fernandes, Leo and Ribeiro, M{\'a}rcio},
  journal={Journal of Systems and Software},
  volume={157},
  pages={110388},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{regexpMut,
 author = {Groce, Alex and Holmes, Josie and Marinov, Darko and Shi, August and Zhang, Lingming},
 title = {An Extensible, Regular-expression-based Tool for Multi-language Mutant Generation},
 booktitle = {International Conference on Software Engineering: Companion Proceeedings},
 series = {ICSE 2018},
 year = {2018},
 isbn = {978-1-4503-5663-3},
 location = {Gothenburg, Sweden},
 pages = {25--28},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3183440.3183485},
 doi = {10.1145/3183440.3183485},
 acmid = {3183485},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {multi-language tools, mutation testing, regular expressions},
} 


@incollection{MutationSurvey,
  title={Mutation testing advances: an analysis and survey},
  author={Papadakis, Mike and Kintis, Marinos and Zhang, Jie and Jia, Yue and Le Traon, Yves and Harman, Mark},
  booktitle={Advances in Computers},
  volume={112},
  pages={275--378},
  year={2019},
  publisher={Elsevier}
}

@article{offutt1997automatically,
  title={Automatically detecting equivalent mutants and infeasible paths},
  author={Offutt, A Jefferson and Pan, Jie},
  journal={Software testing, verification and reliability},
  volume={7},
  number={3},
  pages={165--192},
  year={1997},
  publisher={Wiley Online Library}
}


@misc{dataset-small,
  title={Directory of ERC20 tokens},
  author={Trust Wallet},
  howpublished = "\url{https://github.com/TrustWallet/tokens}",
  year={2018}
}

@inproceedings{contractfuzzer,
  title={Contractfuzzer: Fuzzing smart contracts for vulnerability detection},
  author={Jiang, Bo and Liu, Ye and Chan, WK},
  booktitle={International Conference on Automated Software Engineering},
  pages={259--269},
  year={2018}
}

@misc{solfuzz,
  howpublished="\url{https://github.com/b-mueller/solfuzz}",
  author = "Bernhard Mueller"
  }

@inproceedings{Pacheco,
  author = "Carlos Pacheco and Shuvendu K. Lahiri and Michael D. Ernst and Thomas Ball",
  title = "Feedback-directed Random Test Generation",
  booktitle = "International Conference on Software Engineering",
  year = "2007",
  pages = "75--84"
}

@misc{albert2019gasol,
    title={GASOL: Gas Analysis and Optimization for Ethereum Smart Contracts},
    author={Elvira Albert and Jesús Correas and Pablo Gordillo and Guillermo Román-Díez and Albert Rubio},
    year={2019},
    eprint={1912.11929},
    archivePrefix={arXiv},
    primaryClass={cs.PL}
}

@INPROCEEDINGS{eclipser,
  author = {Jaeseung Choi and Joonun Jang and Choongwoo Han and Sang Kil Cha},
  title = {Grey-box Concolic Testing on Binary Code},
  booktitle = {International Conference on Software Engineering},
  pages = {736--747},
  year = 2019
}

@book{ewd,
editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
title = {Structured Programming},
year = {1972},
isbn = {0122005503},
publisher = {Academic Press Ltd.},
address = {GBR},
abstract = {In recent years there has been an increasing interest in the art of computer programming,
the conceptual tools available for the design of programs, and the prevention of programming
oversights and error. The initial outstanding contribution to our understanding of
this subject was made by E. W. Dijkstra, whose Notes on Structured Programming form
the first and major section of this book. They clearly expound the reflections of
a brilliant programmer on the methods which he has hitherto unconsciously applied;
there can be no programmer of the present day who could not increase his skills by
a study and conscious application of these principles.In the second monograph I have
tried to describe how similar principles can be applied in the design of data structures.
I have suggested that in analysing a problem and groping towards a solution, a programmer
should take advantage of abstract concepts such as sets, sequences, and mappings;
and judiciously postpone decisions on representation until he is constructing the
more detailed code of the program. The monograph also describes a range of useful
ideas for data representation, and suggests the criteria relevant for their selection.The
third monograph provides a synthesis of the previous two, and expounds the close theoretical
and practical connections between the design of data and the design of programs. It
introduces useful additional methods for program and data structuring which may be
unfamiliar to many programmers. The examples show that structured programming principles
can be equally applied in "bottom-up" as in "top-down" program design. The original
inspiration, insight, and all the examples were contributed by O.-J. Dahl; I have
only assembled the material, and added some additional explanations where I found
it difficult to understand.}
}

@inproceedings{covdev,
author = {Gopinath, Rahul and Jensen, Carlos and Groce, Alex},
title = {Code Coverage for Suite Evaluation by Developers},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568278},
doi = {10.1145/2568225.2568278},
abstract = { One of the key challenges of developers testing code is determining a test suite's
quality -- its ability to find faults. The most common approach is to use code coverage
as a measure for test suite quality, and diminishing returns in coverage or high absolute
coverage as a stopping rule. In testing research, suite quality is often evaluated
by a suite's ability to kill mutants (artificially seeded potential faults). Determining
which criteria best predict mutation kills is critical to practical estimation of
test suite quality. Previous work has only used small sets of programs, and usually
compares multiple suites for a single program. Practitioners, however, seldom compare
suites --- they evaluate one suite. Using suites (both manual and automatically generated)
from a large set of real-world open-source projects shows that evaluation results
differ from those for suite-comparison: statement (not block, branch, or path) coverage
predicts mutation kills best. },
booktitle = {International Conference on Software Engineering},
pages = {72–82},
numpages = {11},
keywords = {test frameworks, evaluation of coverage criteria, statistical analysis},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{papadakis2018mutant,
  title={Mutant quality indicators},
  author={Papadakis, Mike and Chekam, Thierry Titcheu and Le Traon, Yves},
  booktitle={2018 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)},
  pages={32--39},
  year={2018},
  organization={IEEE}
}

@inproceedings{PetrovicTestingPractices,
  author    = {Goran Petrovic and
               Marko Ivankovic and
               Gordon Fraser and
               Ren{\'{e}} Just},
  title     = {Does mutation testing improve testing practices?},
  booktitle = {International Conference on Software Engineering},
  pages     = {910--921},
  publisher = {{IEEE}},
  year      = {2021},
  url       = {https://doi.org/10.1109/ICSE43902.2021.00087},
  doi       = {10.1109/ICSE43902.2021.00087},
  timestamp = {Sun, 25 Jul 2021 11:48:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icse/PetrovicIFJ21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DelgadoPerezCaseStudy,
  author    = {Pedro Delgado{-}P{\'{e}}rez and
               Ibrahim Habli and
               Steve Gregory and
               Rob Alexander and
               John A. Clark and
               Inmaculada Medina{-}Bulo},
  title     = {Evaluation of Mutation Testing in a Nuclear Industry Case Study},
  journal   = {{IEEE} Trans. Reliab.},
  volume    = {67},
  number    = {4},
  pages     = {1406--1419},
  year      = {2018},
  url       = {https://doi.org/10.1109/TR.2018.2864678},
  doi       = {10.1109/TR.2018.2864678},
  timestamp = {Thu, 09 Jul 2020 22:47:00 +0200},
  biburl    = {https://dblp.org/rec/journals/tr/Delgado-PerezHG18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{KaufmanFAKAJ2022,
   author = {Samuel J. Kaufman and Ryan Featherman and Justin Alvin and
	Bob Kurtz and Paul Ammann and Ren{\'e} Just},
   title = {Prioritizing Mutants to Guide Mutation Testing},
   booktitle = {Proceedings of the International Conference on Software
	Engineering (ICSE)},
   month = {May~25--27},
   year = {2022}
}


@inproceedings{zhang2016pmt,
author = {Zhang, Jie and Wang, Ziyi and Zhang, Lingming and Hao, Dan and Zang, Lei and Cheng, Shiyang and Zhang, Lu},
title = {Predictive Mutation Testing},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2931038},
doi = {10.1145/2931037.2931038},
abstract = { Mutation testing is a powerful methodology for evaluating test suite quality. In mutation testing, a large number of mutants are generated and executed against the test suite to check the ratio of killed mutants. Therefore, mutation testing is widely believed to be a computationally expensive technique. To alleviate the efficiency concern of mutation testing, in this paper, we propose predictive mutation testing (PMT), the first approach to predicting mutation testing results without mutant execution. In particular, the proposed approach constructs a classification model based on a series of features related to mutants and tests, and uses the classification model to predict whether a mutant is killed or survived without executing it. PMT has been evaluated on 163 real-world projects under two application scenarios (i.e., cross-version and cross-project). The experimental results demonstrate that PMT improves the efficiency of mutation testing by up to 151.4X while incurring only a small accuracy loss when predicting mutant execution results, indicating a good tradeoff between efficiency and effectiveness of mutation testing. },
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {342–353},
numpages = {12},
keywords = {software testing, mutation testing, machine learning},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}


@incollection{offutt2001mutation,
  title={Mutation 2000: Uniting the orthogonal},
  author={Offutt, A Jefferson and Untch, Roland H},
  booktitle={Mutation testing for the new century},
  pages={34--44},
  year={2001},
  publisher={Springer}
}


@article{untch1993mutation,
author = {Untch, Roland H. and Offutt, A. Jefferson and Harrold, Mary Jean},
title = {Mutation Analysis Using Mutant Schemata},
year = {1993},
issue_date = {July 1993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/174146.154265},
doi = {10.1145/174146.154265},
abstract = {Mutation analysis is a powerful technique for assessing and improving the quality of test data used to unit test software. Unfortunately, current automated mutation analysis systems suffer from severe performance problems. This paper presents a new method for performing mutation analysis that uses program schemata to encode all mutants for a program into one metaprogram, which is subsequently compiled and run at speeds substantially higher than achieved by previous interpretive systems. Preliminary performance improvements of over 300% are reported. This method has the additional advantages of being easier to implement than interpretive systems, being simpler to port across a wide range of hardware and software platforms, and using the same compiler and run-time support system that is used during development and/or deployment.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {jul},
pages = {139–148},
numpages = {10},
keywords = {fault-based testing, mutation analysis, program schemata, software testing}
}



@article{offuttMutant1996,
author = {Offutt, A. Jefferson and Lee, Ammei and Rothermel, Gregg and Untch, Roland H. and Zapf, Christian},
title = {An Experimental Determination of Sufficient Mutant Operators},
year = {1996},
issue_date = {April 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/227607.227610},
doi = {10.1145/227607.227610},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
pages = {99–118},
numpages = {20}
}


@article{kim2022predictive,
author = {Kim, Jinhan and Jeon, Juyoung and Hong, Shin and Yoo, Shin},
title = {Predictive Mutation Analysis via the Natural Language Channel in Source Code},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3510417},
doi = {10.1145/3510417},
abstract = {Mutation analysis can provide valuable insights into both the system under test and its test suite. However, it is not scalable due to the cost of building and testing a large number of mutants. Predictive Mutation Testing (PMT) has been proposed to reduce the cost of mutation testing, but it can only provide statistical inference about whether a mutant will be killed or not by the entire test suite. We propose Seshat, a Predictive Mutation Analysis (PMA) technique that can accurately predict the entire kill matrix, not just the Mutation Score (MS) of the given test suite. Seshat exploits the natural language channel in code, and learns the relationship between the syntactic and semantic concepts of each test case and the mutants it can kill, from a given kill matrix. The learnt model can later be used to predict the kill matrices for subsequent versions of the program, even after both the source and test code have changed significantly. Empirical evaluation using the programs in Defects4J shows that Seshat can predict kill matrices with an average F-score of 0.83 for versions that are up to years apart. This is an improvement in F-score by 0.14 and 0.45 points over the state-of-the-art PMT technique and a simple coverage-based heuristic, respectively. Seshat also performs as well as PMT for the prediction of the MS only. When applied to a mutant-based fault localisation technique, the predicted kill matrix by Seshat is successfully used to locate faults within the top 10 position, showing its usefulness beyond prediction of MS. Once Seshat trains its model using a concrete mutation analysis, the subsequent predictions made by Seshat are on average 39 times faster than actual test-based analysis. We also show that Seshat can be successfully applied to automatically generated test cases with an experiment using EvoSuite.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
articleno = {73},
numpages = {27},
keywords = {deep learning, Mutation analysis}
}

@INPROCEEDINGS{CompareSrcBinary,
  author={Hariri, Farah and Shi, August and Fernando, Vimuth and Mahmood, Suleman and Marinov, Darko},
  booktitle={2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)}, 
  title={Comparing Mutation Testing at the Levels of Source Code and Compiler Intermediate Representation}, 
  year={2019},
  volume={},
  number={},
  pages={114-124},
  doi={10.1109/ICST.2019.00021}}

@article{gopinath2017mutation,
  title={Mutation reduction strategies considered harmful},
  author={Gopinath, Rahul and Ahmed, Iftekhar and Alipour, Mohammad Amin and Jensen, Carlos and Groce, Alex},
  journal={IEEE Transactions on Reliability},
  volume={66},
  number={3},
  pages={854--874},
  year={2017},
  publisher={IEEE}
}

@article{CommACMJavaTool,
author = {Amalfitano, Domenico and Paiva, Ana C. R. and Inquel, Alexis and Pinto, Lu\'{\i}s and Fasolino, Anna Rita and Just, Ren\'{e}},
title = {How Do Java Mutation Tools Differ?},
year = {2022},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {65},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3526099},
doi = {10.1145/3526099},
abstract = {A framework for aiding future Java mutation tool comparisons.},
journal = {Commun. ACM},
month = {nov},
pages = {74–89},
numpages = {16}
}



@INPROCEEDINGS{MajorPIT,
  author={Kintis, Marinos and Papadakis, Mike and Papadopoulos, Andreas and Valvis, Evangelos and Malevris, Nicos},
  booktitle={2016 IEEE 16th International Working Conference on Source Code Analysis and Manipulation (SCAM)}, 
  title={Analysing and Comparing the Effectiveness of Mutation Testing Tools: A Manual Study}, 
  year={2016},
  volume={},
  number={},
  pages={147-156},
  doi={10.1109/SCAM.2016.28}}

@article{gopinath2017does,
  title={Does choice of mutation tool matter?},
  author={Gopinath, Rahul and Ahmed, Iftekhar and Alipour, Mohammad Amin and Jensen, Carlos and Groce, Alex},
  journal={Software Quality Journal},
  volume={25},
  pages={871--920},
  year={2017},
  publisher={Springer}
}


@inproceedings{GopinathSampleSize,
  author    = {Rahul Gopinath and
               Amin Alipour and
               Iftekhar Ahmed and
               Carlos Jensen and
               Alex Groce},
  title     = {How hard does mutation analysis have to be, anyway?},
  booktitle = {International Symposium on Software Reliability Engineering},
  pages     = {216--227},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  url       = {https://doi.org/10.1109/ISSRE.2015.7381815},
  doi       = {10.1109/ISSRE.2015.7381815},
  timestamp = {Thu, 14 Oct 2021 09:59:10 +0200},
  biburl    = {https://dblp.org/rec/conf/issre/GopinathAAJG15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/1294211.1294256,
author = {Olsen, Dan R.},
title = {Evaluating User Interface Systems Research},
year = {2007},
isbn = {9781595936790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294211.1294256},
doi = {10.1145/1294211.1294256},
abstract = {The development of user interface systems has languished with the stability of desktop
computing. Future systems, however, that are off-the-desktop, nomadic or physical
in nature will involve new devices and new software systems for creating interactive
applications. Simple usability testing is not adequate for evaluating complex systems.
The problems with evaluating systems work are explored and a set of criteria for evaluating
new UI systems work is presented.},
booktitle = {Symposium on User Interface Software and Technology},
pages = {251–258},
numpages = {8},
keywords = {user interface systems evaluation},
location = {Newport, Rhode Island, USA},
series = {UIST '07}
}



@misc{ma2019gasfuzz,
    title={GasFuzz: Generating High Gas Consumption Inputs to Avoid Out-of-Gas Vulnerability},
    author={Fuchen Ma and Ying Fu and Meng Ren and Wanting Sun and Zhe Liu and Yu Jiang and Jun Sun and Jiaguang Sun},
    year={2019},
    eprint={1910.02945},
    archivePrefix={arXiv},
    primaryClass={cs.CR}
}

@inproceedings{lemieux2018perffuzz,
  title={Perffuzz: Automatically generating pathological inputs},
  author={Lemieux, Caroline and Padhye, Rohan and Sen, Koushik and Song, Dawn},
  booktitle={International Symposium on Software Testing and Analysis},
  pages={254--265},
  year={2018}
}

@article{swarmIEEE,
  author = "Gerard Holzmann and Rajeev Joshi and Alex Groce",
  title = "Swarm Verification Techniques",
  journal = "IEEE Transactions on Software Engineering",
volume = {37},
number = {6},
  year = 2011,
  pages = "845--857"
}


@inproceedings{groce2013help,
  title={Help, help, {I'm} being suppressed! The significance of suppressors in software testing},
  author={Groce, Alex and Zhang, Chaoqiang and Alipour, Mohammad Amin and Eide, Eric and Chen, Yang and Regehr, John},
  booktitle={International Symposium on Software Reliability Engineering},
  pages={390--399},
  year={2013},
  organization={IEEE}
}

@inproceedings{ASE08,
  author = "James H. Andrews and Alex Groce and Melissa Weston and Ru-Gang Xu",
  title = "Random Test Run Length and Effectiveness",
  booktitle = "Automated Software Engineering",
pages = "19--28",
  year = 2008
}

@inproceedings{ISSTA12,
  author = "Alex Groce and Chaoqiang Zhang and Eric Eide and Yang Chen and John Regehr",
  title = "Swarm Testing",
  booktitle = "International Symposium on Software Testing and Analysis",
  year = 2012,
  pages = "78--88"
}

@inproceedings{zhong2018generating,
  title={Generating regular expressions from natural language specifications: Are we there yet?},
  author={Zhong, Zexuan and Guo, Jiaqi and Yang, Wei and Xie, Tao and Lou, Jian-Guang and Liu, Ting and Zhang, Dongmei},
  booktitle={AAAI Workshops},
  pages={791--794},
  year={2018}
}

@article{bartoli2014automatic,
  title={Automatic synthesis of regular expressions from examples},
  author={Bartoli, Alberto and Davanzo, Giorgio and De Lorenzo, Andrea and Medvet, Eric and Sorio, Enrico},
  journal={Computer},
  volume={47},
  number={12},
  pages={72--80},
  year={2014},
  publisher={IEEE}
}

@inproceedings{deng2013empirical,
  title={Empirical evaluation of the statement deletion mutation operator},
  author={Deng, Lin and Offutt, Jeff and Li, Nan},
  booktitle={2013 IEEE Sixth International Conference on Software Testing, Verification and Validation},
  pages={84--93},
  year={2013},
  organization={IEEE}
}

@book{SPIN,
  author="Gerard J. Holzmann",
  title="The {SPIN} Model Checker: Primer and Reference Manual",
  publisher="Addison-Wesley Professional",
  year="2003"}

@misc{chainfuzz,
  howpublished="\url{https://github.com/ChainSecurity/ChainFuzz}",
  author="{Chain Security}"
  }

@inproceedings{oyente,
 author = {Luu, Loi and Chu, Duc-Hiep and Olickel, Hrishi and Saxena, Prateek and Hobor, Aquinas},
 title = {Making Smart Contracts Smarter},
 series = {CCS '16},
 year = {2016},
} 
@inproceedings{AFLplusplus-Woot20,
	author = {Andrea Fioraldi and Dominik Maier and Heiko Ei{\ss}feldt and Marc Heuse},
	title = {AFL++ : Combining Incremental Steps of Fuzzing Research},
	booktitle = {{USENIX} Workshop on Offensive Technologies},
	year = {2020},
	url = {https://www.usenix.org/conference/woot20/presentation/fioraldi},
	publisher = {{USENIX} Association},
	month = aug,
}

@inproceedings{QASan-SecDev20,
  author={Fioraldi, Andrea and D’Elia, Daniele Cono and Querzoni, Leonardo},
  booktitle={Secure Development Conference}, 
  title={Fuzzing Binaries for Memory Safety Errors with {QASan}}, 
  year={2020}
}

@inproceedings{BaseSAFE-WiSec20,
  author = {Maier, Dominik and Seidel, Lukas and Park, Shinjo},
  title = {BaseSAFE: Baseband Sanitized Fuzzing through Emulation},
  year = {2020},
  isbn = {9781450380065},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3395351.3399360},
  doi = {10.1145/3395351.3399360},
  booktitle = {Conference on Security and Privacy in Wireless and Mobile Networks},
  pages = {122--132},
  numpages = {11},
  keywords = {rehosting, cellular, fuzzing, security},
  location = {Linz, Austria},
  series = {WiSec '20}
}

@inproceedings{FuzzingSymbolicExpressions-ICSE21,
  author={Borzacchiello, Luca and Coppa, Emilio and Demetrescu, Camil},
  booktitle={International Conference on Software Engineering},
  title={Fuzzing Symbolic Expressions},
  year={2021},
  volume={},
  number={},
  pages={711-722},
  doi={10.1109/ICSE43902.2021.00071}
}

@inproceedings{PMFuzz-ASPLOS21,
  title={PMFuzz: Test Case Generation for Persistent Memory Programs},
  author={Liu, Sihang and Mahar, Suyash and Ray, Baishakhi and Khan, Samira},
  booktitle={International Conference on Architectural Support for Programming Languages and Operating Systems},
  year={2021}
}

@inproceedings {InvsCov-USENIX21,
  author = {Andrea Fioraldi and Daniele Cono D'Elia and Davide Balzarotti},
  title = {The Use of Likely Invariants as Feedback for Fuzzers},
  booktitle = {{USENIX} Security Symposium},
  year = {2021},
  url = {https://www.usenix.org/conference/usenixsecurity21/presentation/fioraldi},
  publisher = {{USENIX} Association},
  month = aug,
}

@inproceedings{Gramatron-ISSTA21,
  author = {Srivastava, Prashast and Payer, Mathias},
  title = {Gramatron: Effective Grammar-Aware Fuzzing},
  year = {2021},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {http://nebelwelt.net/files/21ISSTA.pdf},
  doi = {10.1145/3460319.3464814},
  booktitle = {International Symposium on Software Testing and Analysis},
  keywords = {Fuzzing, grammar-aware, dynamic software analysis},
  location = {Virtual, Denmark},
  series = {ISSTA 2021}
}

@inproceedings{goodman2018deepstate,
  title={{DeepState}: Symbolic unit testing for {C} and {C++}},
  author={Goodman, Peter and Groce, Alex},
  booktitle={NDSS Workshop on Binary Analysis Research},
  year={2018}
}

@inproceedings{jiang:ase:2018,
  author = {Jiang, Bo and Liu, Ye and Chan, W. K.},
  title = {{ContractFuzzer}: Fuzzing Smart Contracts for Vulnerability Detection},
  year = {2018},
  booktitle={International Conference on Automated Software Engineering},
  pages = {259--269}
}

@inproceedings{harvey,
  title = {Harvey: A Greybox Fuzzer for Smart Contracts},
  author = {W{\"u}stholz, Valentin and Christakis, Maria},
  booktitle = {Foundations of
    Software Engineering},
  pages = {1398--1409},
  year = 2020
}

@inproceedings{sfuzz,
author = {Nguyen, Tai D. and Pham, Long H. and Sun, Jun and Lin, Yun and Minh, Quang Tran},
title = {{SFuzz}: An Efficient Adaptive Fuzzer for {Solidity} Smart Contracts},
year = {2020},

booktitle = {International Conference on Software Engineering},
pages = {778–788}
}

@inproceedings{he2019learning,
  title={Learning to fuzz from symbolic execution with application to smart contracts},
  author={He, Jingxuan and Balunovi{\'c}, Mislav and Ambroladze, Nodar and Tsankov, Petar and Vechev, Martin},
  booktitle={ Conference on Computer and Communications Security},
  pages={531--548},
  year={2019}
}

@article{dietterich2002ensemble,
  title={Ensemble learning},
  author={Dietterich, Thomas G and others},
  journal={The handbook of brain theory and neural networks},
  volume={2},
  pages={110--125},
  year={2002},
  publisher={MIT press Cambridge, Massachusetts}
}

@inproceedings{zhou2021foundationdb,
  title={{FoundationDB:} A Distributed Unbundled Transactional Key Value Store},
  author={Zhou, Jingyu and Xu, Meng and Shraer, Alexander and Namasivayam, Bala and Miller, Alex and Tschannen, Evan and Atherton, Steve and Beamon, Andrew J and Sears, Rusty and Leach, John and others},
  year={2021},
  booktitle={{ACM} {SIGMOD}}
}

@article{le2014compiler,
  title={Compiler validation via equivalence modulo inputs},
  author={Le, Vu and Afshari, Mehrdad and Su, Zhendong},
  journal={ACM SIGPLAN Notices},
  volume={49},
  number={6},
  pages={216--226},
  year={2014},
  publisher={ACM New York, NY, USA}
}


@inproceedings{chen2019enfuzz,
  title={Enfuzz: Ensemble fuzzing with seed synchronization among diverse fuzzers},
  author={Chen, Yuanliang and Jiang, Yu and Ma, Fuchen and Liang, Jie and Wang, Mingzhe and Zhou, Chijin and Jiao, Xun and Su, Zhuo},
  booktitle={{USENIX} Security Symposium},
  pages={1967--1983},
  year={2019}
}

@inproceedings{dewey2015fuzzing,
  title={Fuzzing the Rust typechecker using CLP (T)},
  author={Dewey, Kyle and Roesch, Jared and Hardekopf, Ben},
  booktitle={International Conference on Automated Software Engineering},
  pages={482--493},
  year={2015},
  organization={IEEE}
}



@misc{solidityj-code,
  title={Solidity grammar for ANTLR4 },
  author={Federico Bond},
  howpublished = "\url{https://github.com/solidityj/solidity-antlr4}",
  year={2017}
}



@inproceedings{10.1145/2491956.2462173,
author = {Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
title = {Taming Compiler Fuzzers},
year = {2013},
isbn = {9781450320146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491956.2462173},
doi = {10.1145/2491956.2462173},
abstract = {Aggressive random testing tools ("fuzzers") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.},
booktitle = {Conference on Programming Language Design and Implementation},
pages = {197–208},
numpages = {12},
keywords = {automated testing, compiler testing, random testing, compiler defect, test-case reduction, bug reporting, fuzz testing},
location = {Seattle, Washington, USA},
series = {PLDI '13}
}


@inproceedings{Taming,
author = {Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
title = {Taming Compiler Fuzzers},
year = {2013},
url = {https://doi.org/10.1145/2499370.2462173},
doi = {10.1145/2499370.2462173},
abstract = {Aggressive random testing tools ("fuzzers") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.},
booktitle={Symposium on Programming Language Design and Implementation},
month = jun,
pages = {197–208},
numpages = {12},
keywords = {fuzz testing, compiler testing, compiler defect, test-case reduction, random testing, bug reporting, automated testing}
}

@article{coupon,
  title={Asymptotic distributions for the coupon collector's problem},
  author={Baum, Leonard E and Billingsley, Patrick},
  journal={The Annals of Mathematical Statistics},
  volume={36},
  number={6},
  pages={1835--1839},
  year={1965},
  publisher={JSTOR}
}

@INPROCEEDINGS{Multilingual,
  author={Hong, Shin and Lee, Byeongcheol and Kwak, Taehoon and Jeon, Yiru and Ko, Bongsuk and Kim, Yunho and Kim, Moonzoo},
  booktitle={2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Mutation-Based Fault Localization for Real-World Multilingual Programs (T)}, 
  year={2015},
  volume={},
  number={},
  pages={464-475},
  doi={10.1109/ASE.2015.14}}

@article{Gonzalez85,
  author = "Teofilo F. Gonzalez",
  title = "Clustering to Minimize the Maximum Intercluster Distance",
  journal = "Theoretical Computer Science",
  volume = 38,
  year = 1985,
  pages = "293--306",
}

@misc{mutantSlow,
  howpublished = "\url{https://solidsoft.wordpress.com/2017/09/19/how-fast-or-slow-mutation-testing-really-is/}",
title = "How fast (or slow) mutation testing really is?"
}



@misc{webassembly,
  title={WebAssembly},
  howpublished = "\url{http://webassembly.org/}",
  year={2016}
}

@inproceedings{securify,
 author = {Tsankov, Petar and Dan, Andrei and Drachsler-Cohen, Dana and Gervais, Arthur and B\"{u}nzli, Florian and Vechev, Martin},
 title = {Securify: Practical Security Analysis of Smart Contracts},
 series = {CCS 2018},
 year = {2018},
}

@inproceedings{pseudotestingorig,
author = {Niedermayr, Rainer and Juergens, Elmar and Wagner, Stefan},
title = {Will My Tests Tell Me If I Break This Code?},
year = {2016},
isbn = {9781450341578},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896941.2896944},
doi = {10.1145/2896941.2896944},
abstract = {Automated tests play an important role in software evolution because they can rapidly detect faults introduced during changes. In practice, code-coverage metrics are often used as criteria to evaluate the effectiveness of test suites with focus on regression faults. However, code coverage only expresses which portion of a system has been executed by tests, but not how effective the tests actually are in detecting regression faults.Our goal was to evaluate the validity of code coverage as a measure for test effectiveness. To do so, we conducted an empirical study in which we applied an extreme mutation testing approach to analyze the tests of open-source projects written in Java. We assessed the ratio of pseudo-tested methods (those tested in a way such that faults would not be detected) to all covered methods and judged their impact on the software project. The results show that the ratio of pseudo-tested methods is acceptable for unit tests but not for system tests (that execute large portions of the whole system). Therefore, we conclude that the coverage metric is only a valid effectiveness indicator for unit tests.},
booktitle = {International Workshop on Continuous Software Evolution and Delivery},
pages = {23–29},
numpages = {7},
keywords = {test suite effectiveness, regression testing, mutation testing, code coverage},
location = {Austin, Texas},
series = {CSED '16}
}

@inproceedings{descartes,
author = {Vera-P\'{e}rez, Oscar Luis and Monperrus, Martin and Baudry, Benoit},
title = {Descartes: A PITest Engine to Detect Pseudo-Tested Methods: Tool Demonstration},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240474},
doi = {10.1145/3238147.3240474},
abstract = {Descartes is a tool that implements extreme mutation operators and aims at finding pseudo-tested methods in Java projects. It leverages the efficient transformation and runtime features of PITest. The demonstration compares Descartes with Gregor, the default mutation engine provided by PITest, in a set of real open source projects. It considers the execution time, number of mutants created and the relationship between the mutation scores produced by both engines. It provides some insights on the main features exposed byDescartes.},
booktitle = {International Conference on Automated Software Engineering},
pages = {908–911},
numpages = {4},
keywords = {pseudo-tested methods, mutation testing, extreme mutation, software testing, PITest},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{pit,
author = {Coles, Henry and Laurent, Thomas and Henard, Christopher and Papadakis, Mike and Ventresque, Anthony},
title = {PIT: A Practical Mutation Testing Tool for Java (Demo)},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2948707},
doi = {10.1145/2931037.2948707},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {449–452},
numpages = {4},
keywords = {Automated Tool, PIT, Mutation Testing},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}


@article{pseudotestingstudy,
author = {Vera-P\'{e}rez, Oscar Luis and Danglot, Benjamin and Monperrus, Martin and Baudry, Benoit},
title = {A Comprehensive Study of Pseudo-Tested Methods},
year = {2019},
issue_date = {Jun 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9653-2},
doi = {10.1007/s10664-018-9653-2},
abstract = {Pseudo-tested methods are defined as follows: they are covered by the test suite, yet no test case fails when the method body is removed, i.e., when all the effects of this method are suppressed. This intriguing concept was coined in 2016, by Niedermayr and colleagues, who showed that such methods are systematically present, even in well-tested projects with high statement coverage. This work presents a novel analysis of pseudo-tested methods. First, we run a replication of Niedermayr's study with 28K+ methods, enhancing its external validity thanks to the use of new tools and new study subjects. Second, we perform a systematic characterization of these methods, both quantitatively and qualitatively with an extensive manual analysis of 101 pseudo-tested methods. The first part of the study confirms Niedermayr's results: pseudo-tested methods exist in all our subjects. Our in-depth characterization of pseudo-tested methods leads to two key insights: pseudo-tested methods are significantly less tested than the other methods; yet, for most of them, the developers would not pay the testing price to fix this situation. This calls for future work on targeted test generation to specify those pseudo-tested methods without spending developer time.},
journal = {Empirical Software Engineering},
month = {jun},
pages = {1195–1225},
numpages = {31},
keywords = {Test quality, Pseudo-tested methods, Program analysis, Software testing, Software developers}
}



@inproceedings{mutationStatementBranchComparison,
  author    = {Thierry Titcheu Chekam and
               Mike Papadakis and
               Yves Le Traon and
               Mark Harman},
  editor    = {Sebasti{\'{a}}n Uchitel and
               Alessandro Orso and
               Martin P. Robillard},
  title     = {An empirical study on mutation, statement and branch coverage fault
               revelation that avoids the unreliable clean program assumption},
  booktitle = {International Conference on Software Engineering},
  pages     = {597--608},
  publisher = {{IEEE} / {ACM}},
  year      = {2017},
  url       = {https://doi.org/10.1109/ICSE.2017.61},
  doi       = {10.1109/ICSE.2017.61},
  timestamp = {Thu, 14 Oct 2021 10:18:32 +0200},
  biburl    = {https://dblp.org/rec/conf/icse/ChekamPTH17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{covComparisons,
  author    = {Milos Gligoric and
               Alex Groce and
               Chaoqiang Zhang and
               Rohan Sharma and
               Mohammad Amin Alipour and
               Darko Marinov},
  title     = {Guidelines for Coverage-Based Comparisons of Non-Adequate Test Suites},
  journal   = {Transactions on Software Engineering and Methodology},
  volume    = {24},
  number    = {4},
  pages     = {22:1--22:33},
  year      = {2015},
  url       = {https://doi.org/10.1145/2660767},
  doi       = {10.1145/2660767},
  timestamp = {Tue, 06 Nov 2018 12:51:20 +0100},
  biburl    = {https://dblp.org/rec/journals/tosem/GligoricGZSAM15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{codeCoverageGoogle,
  author    = {Marko Ivankovic and
               Goran Petrovic and
               Ren{\'{e}} Just and
               Gordon Fraser},
  editor    = {Marlon Dumas and
               Dietmar Pfahl and
               Sven Apel and
               Alessandra Russo},
  title     = {Code coverage at Google},
  booktitle = {Joint Meeting on European Software Engineering
               Conference and Symposium on the Foundations of Software Engineering},
  pages     = {955--963},
  publisher = {{ACM}},
  year      = {2019},
  url       = {https://doi.org/10.1145/3338906.3340459},
  doi       = {10.1145/3338906.3340459},
  timestamp = {Tue, 01 Feb 2022 10:45:16 +0100},
  biburl    = {https://dblp.org/rec/conf/sigsoft/IvankovicPJF19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Discontents,
author = {Groce, Alex and Alipour, Mohammad Amin and Gopinath, Rahul},
title = {Coverage and Its Discontents},
year = {2014},
isbn = {9781450332101},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661136.2661157},
doi = {10.1145/2661136.2661157},
abstract = {Everyone wants to know one thing about a test suite: will it detect enough bugs? Unfortunately, in most settings that matter, answering this question directly is impractical or impossible. Software engineers and researchers therefore tend to rely on various measures of code coverage (where mutation testing is considered a form of syntactic coverage). A long line of academic research efforts have attempted to determine whether relying on coverage as a substitute for fault detection is a reasonable solution to the problems of test suite evaluation. This essay argues that the profusion of coverage-related literature is in part a sign of an underlying uncertainty as to what exactly it is that measuring coverage should achieve, as well as how we would know if it can, in fact, achieve it. We propose some solutions and mitigations, but the primary focus of this essay is to clarify the state of current confusions regarding this key problem for effective software testing.},
booktitle = {International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {255–268},
numpages = {14},
keywords = {evaluation, testing, coverage},
location = {Portland, Oregon, USA},
series = {Onward 2014}
}



@inproceedings{FormalCoupon,
author = {Arcuri, Andrea and Iqbal, Muhammad Zohaib and Briand, Lionel},
title = {Formal Analysis of the Effectiveness and Predictability of Random Testing},
year = {2010},
isbn = {9781605588230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1831708.1831736},
doi = {10.1145/1831708.1831736},
abstract = {There has been a lot of work to shed light on whether random testing is actually a useful testing technique. Despite its simplicity, several successful real-world applications appear in the literature. Although it is not going to solve all possible testing problems, random testing is an essential tool in the hands of software testers. In this paper, we address general questions about random testing, such as how long random testing needs on average to achieve testing targets (e.g., coverage), how does it scale and how likely is it to yield similar results if we re-run random testing on the same testing problem. Due to its simplicity that makes the mathematical analysis of random testing tractable, we provide precise and rigorous answers to these questions. Our formal results can be applied to most types of software and testing criteria. Simulations are carried out to provide further support to our formal results. The obtained results are then used to assess the validity of empirical analyses reported in the literature. Results show that random testing is more effective and predictable than previously thought.},
booktitle = {International Symposium on Software Testing and Analysis},
pages = {219–230},
numpages = {12},
keywords = {random testing, predictability, coupon collector, theory, schur function},
location = {Trento, Italy},
series = {ISSTA '10}
}

@inproceedings{EvoSuite,
author = {Fraser, Gordon and Arcuri, Andrea},
title = {EvoSuite: Automatic Test Suite Generation for Object-Oriented Software},
year = {2011},
isbn = {9781450304436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2025113.2025179},
doi = {10.1145/2025113.2025179},
abstract = {To find defects in software, one needs test cases that execute the software systematically, and oracles that assess the correctness of the observed behavior when running these test cases. This paper presents EvoSuite, a tool that automatically generates test cases with assertions for classes written in Java code. To achieve this, EvoSuite applies a novel hybrid approach that generates and optimizes whole test suites towards satisfying a coverage criterion. For the produced test suites, EvoSuite suggests possible oracles by adding small and effective sets of assertions that concisely summarize the current behavior; these assertions allow the developer to detect deviations from expected behavior, and to capture the current behavior in order to protect against future defects breaking this behavior.},
booktitle = {Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering},
pages = {416–419},
numpages = {4},
keywords = {assertion generation, test case generation, search based soft- ware testing},
location = {Szeged, Hungary},
series = {ESEC/FSE '11}
}



@article{ArcuriLen,
  author    = {Andrea Arcuri},
  title     = {A Theoretical and Empirical Analysis of the Role of Test Sequence
               Length in Software Testing for Structural Coverage},
  journal   = {Transactions on Software Engineering},
  volume    = {38},
  number    = {3},
  pages     = {497--519},
  year      = {2012},
  url       = {https://doi.org/10.1109/TSE.2011.44},
  doi       = {10.1109/TSE.2011.44},
  timestamp = {Wed, 17 May 2017 10:56:38 +0200},
  biburl    = {https://dblp.org/rec/journals/tse/Arcuri12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{ICSEDiff,
  author={Groce, Alex and Holzmann, Gerard and Joshi, Rajeev},
  booktitle={International Conference on Software Engineering}, 
  title={Randomized Differential Testing as a Prelude to Formal Verification}, 
  year={2007},
  volume={},
  number={},
  pages={621-631},
  doi={10.1109/ICSE.2007.68}}

@article{arcuri2014hitchhiker,
title={A hitchhiker's guide to statistical tests for assessing randomized algorithms in software engineering},
author={Arcuri, Andrea and Briand, Lionel},
journal={Software Testing, Verification and Reliability},
volume={24},
number={3},
pages={219--250},
year={2014}
}

@misc{Hypothesis,
author = "David R. MacIver",
title = "Hypothesis: Test faster, fix more",
howpublished = "\url{http://hypothesis.works/}",
year = 2013,
month = "March"
}

@misc{grishchenko2018semantic,
  author = {Ilya Grishchenko and Matteo Maffei and Clara Schneidewind},
  Title = {A Semantic Framework for the Security Analysis of Ethereum smart contracts},
  Year = {2018},
  howpublished = {arXiv:1802.08660},
  note = {Accessed:2018-03-12},
  url = {https://arxiv.org/pdf/1802.08660.pdf},
}

@inproceedings{smartcheck,
 author = {Tikhomirov S. and et al.},
 title = {SmartCheck: Static Analysis of Ethereum Smart Contracts},
 series = {WETSEB},
 year = {2018},
}

@misc{atzei2016survey,
  author = {Nicola Atzei and Massimo Bartoletti and Tiziana Cimoli},
  title = {A survey of attacks on Ethereum smart contracts},
  publisher = {Cryptology ePrint Archive, Report 2016/1007},
  year = {2016},
  month = {Oct},
  note = {Accessed: 2016-11-08},
  url = {https://eprint.iacr.org/2016/1007.pdf},
}

@inproceedings{DBLP:conf/ndss/KalraGDS18,
  author    = {Sukrit Kalra and
               Seep Goel and
               Mohan Dhawan and
               Subodh Sharma},
  title     = {{ZEUS:} Analyzing Safety of Smart Contracts},
  booktitle = {Network and Distributed System Security Symposium},
  year      = {2018},
  crossref  = {DBLP:conf/ndss/2018},
  url       = {http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2018/02/ndss2018\_09-1\_Kalra\_paper.pdf},
  timestamp = {Thu, 09 Aug 2018 10:57:16 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ndss/KalraGDS18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{mao,
  title={The Hundred Flowers Campaign and the Chinese Intellectuals},
  author={MacFarquhar, Roderick},
  year={1966},
  publisher={Praeger},
  city={New York}
  }

@book{cervantes,
  title={Don Quixote},
  author={Cervantes, Miguel de},
  year={1605}
}



@book{chesterton,
  title={The Uses of Diversity: A Book of Essays},
  author={Chesterton, G. K.},
  year = 1920
  }

@book{Montaigne,
 title={Essays},
 author={Montaigne, Michel de},
 year={1595}
 }

@article{Brooks1987NoSB,
  title={No Silver Bullet Essence and Accidents of Software Engineering},
  author={Brooks, Frederic P.},
  journal={Computer},
  year={1987},
  volume={20},
  pages={10-19}
}

@article{Brent2018VandalAS,
  title={Vandal: A Scalable Security Analysis Framework for Smart Contracts},
  author={Lexi Brent and et al.},
  journal={CoRR},
  year={2018},
  volume={abs/1809.03981}
}

@inproceedings{Spirit,
author = "Glenn Reeves and Tracy Neilson",
title = "The {Mars} {Rover} {Spirit} {Flash} Anomaly",
booktitle = "IEEE Aerospace Conference",
year = "2005"
}


@inproceedings {teether,
  author = {Johannes Krupp and Christian Rossow},
  title = {teEther: Gnawing at Ethereum to Automatically Exploit Smart Contracts},
  booktitle = {USENIX Security},
  year = {2018},
}

@INPROCEEDINGS{StatMut,
  author={Groce, Alex and Ahmed, Iftekhar and Feist, Josselin and Grieco, Gustavo and Gesi, Jiri and Meidani, Mehran and Chen, Qihong},
  booktitle={2021 IEEE 21st International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Evaluating and Improving Static Analysis Tools Via Differential Mutation Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={207-218},
  doi={10.1109/QRS54544.2021.00032}}

@article{tstlsttt,
author = "Josie Holmes and Alex Groce and Jervis Pinto and Pranjal Mittal and Pooria Azimi and Kevi
n Kellar and James O'Brien",
title = "{TSTL:} the Template Scripting Testing Language",
journal = "International Journal on Software Tools for Technology Transfer",
year = 2018,
volume=20,
number =1,
pages="57--78"
}


@inproceedings{WODACommon,
author = {Groce, Alex and Erwig, Martin},
title = {Finding Common Ground: Choose, Assert, and Assume},
booktitle = {International Workshop on Dynamic Analysis},
year = {2012},
pages = {12--17}
} 


@misc{ethertrust,
  title={EtherTrust: Sound Static Analysis of Ethereum bytecode},
  author={Ilya Grishchenko and Matteo Maffei and Clara Schneidewind},
  year={2018}
}

@inproceedings{maian,
  author = {Nikolic, Ivica and Kolluri, Aashish and Sergey, Ilya and Saxena, Prateek and Hobor, Aquinas},
  booktitle = {ACSAC},
  title = {Finding The Greedy, Prodigal, and Suicidal Contracts at Scale},
  year = {2018}
}

@inproceedings{FC20,
  title={What are the Actual Flaws in Important Smart Contracts (and How Can We Find Them)?},
  author={Alex Groce and Josselin Feist and Gustavo Grieco and Michael Colburn},
  year={2020},
  booktitle="International Conference on Financial Cryptography and Data Security",
  pages={634--653}
}

@article{groce2018verified,
  title={How verified (or tested) is my code? falsification-driven verification and testing},
  author={Groce, Alex and Ahmed, Iftekhar and Jensen, Carlos and McKenney, Paul E and  Holmes, Josie},
  journal={Automated Software Engineering Journal},
  year={2018},
 volume = 25,
 number = 4,
 pages = "917--960"
}

@article{demillo1978hints,
  title={Hints on test data selection: Help for the practicing programmer},
  author="Richard J. Lipton and Richard A DeMillo and Frederick G Sayward",
  journal={Computer},
  volume={11},
  number={4},
  pages={34--41},
  year={1978},
  publisher={IEEE}
}


@book{budd1979mutation,
  title={Mutation analysis},
  author="Timothy Budd and Richard J. Lipton and Richard A DeMillo and Frederick G Sayward",
  year={1979},
  publisher={Yale University, Department of Computer Science}
}


@inproceedings{universalMutator,
  author={Groce, Alex and Holmes, Josie and Marinov, Darko and Shi, August and Zhang, Lingming},
  booktitle={International Conference on Software Engineering: Companion}, 
  title={An Extensible, Regular-Expression-Based Tool for Multi-language Mutant Generation}, 
  year={2018},
  volume={},
  number={},
  pages={25-28},
  doi={}}


@inproceedings{mutKernel,
  author = "Iftekhar Ahmed and Carlos Jensen and Alex Groce and Paul E. McKenney",
  title = "Applying Mutation Analysis on Kernel Test Suites: an Experience Report",
  year = 2017,
  month = "March",
  pages = "110--115",
  booktitle = "International Workshop on Mutation Analysis"
  }



@inproceedings{SSA,
  author = {Rosen, Barry K. and Wegman, Mark N. and Zadeck, F. Kenneth},
  booktitle = {POPL},
  title = {Global Value Numbers and Redundant Computations},
  year = {1988}
}


@misc{scilla,
  title={SCILLA Safe-By-Design Smart Contract Language},
  author={Zilliqa},
  howpublished = "\url{https://scilla-lang.org/}",
  year={Accessed on Jan 10, 2019}
}

@misc{michelson,
  title={Michelson: the language of Smart Contracts in Tezos},
  author={Tezos},
  howpublished = "\url{http://www.liquidity-lang.org/doc/reference/michelson.html}",
  year={Accessed on Jan 10, 2019}
}

@article{Differential,
author = "William McKeeman",
title = "Differential testing for software",
journal = "Digital Technical Journal of Digital Equipment Corporation",
volume = "10(1)",
pages = "100--107",
year = 1998
}

@article{barr2014oracle,
  title={The oracle problem in software testing: A survey},
  author={Barr, Earl T and Harman, Mark and McMinn, Phil and Shahbaz, Muzammil and Yoo, Shin},
  journal={Transactions on Software Engineering},
  volume={41},
  number={5},
  pages={507--525},
  year={2014},
  publisher={IEEE}
}

@article{holzmann2006power,
  title={The power of 10: Rules for developing safety-critical code},
  author={Holzmann, Gerard J},
  journal={Computer},
  volume={39},
  number={6},
  pages={95--99},
  year={2006},
  publisher={IEEE}
}

@techreport{iele,
    author = "Kasampalis, Theodoros and et al.",
    year = "2018",
    number = "http://hdl.handle.net/2142/100320",
    title = "IELE: An Intermediate-Level Blockchain Language Designed and Implemented Using Formal Semantics"
}

@misc{yul,
  title={Yul},
  author={Solidity},
  howpublished = "\url{https://solidity.readthedocs.io/en/v0.5.0/yul.html}",
  year={Accessed on Jan 10, 2019}
}

@inproceedings{BMC,
  author = "Armin Biere and Alessandro Cimatti and Edmund M. Clarke and Yunshan Zhu",
  title = "Symbolic Model Checking without {BDDs}",
  booktitle = "Tools and Algorithms for the Construction and Analysis of Systems", 
  year = "1999",
  pages = "193--207"
}

@ARTICLE{McMinn04search-basedsoftware,
author = {Phil McMinn},
title = {Search-based Software Test Data Generation: A Survey},
journal = {Software Testing, Verification and Reliability},
year = {2004},
volume = {14},
pages = {105--156}
}

@inproceedings{CBMCp,
  author = "Daniel Kroening and Edmund M. Clarke and Flavio Lerda",
  title = "A Tool for Checking {ANSI-C} Programs",
  booktitle = "Tools and Algorithms for the Construction and Analysis of Systems",
  year = "2004",
  pages = "168--176"
}

@misc{CBMC,
  howpublished = "\url{https://www.cprover.org/cbmc/}"
}

@inproceedings{vanTonderPPC,
  author = {{van~Tonder}, Rijnard and {Le~Goues}, Claire},
  booktitle = {Conference on Programming language Design and Implementation},
  series = {PLDI '19},
  title = {Lightweight Multi-Language Syntax Transformation with Parser Parser Combinators},
  year = {2019},
}
